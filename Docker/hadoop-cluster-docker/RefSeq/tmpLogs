

Container: container_1550090358635_0074_01_000089 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1550090358635_0074_01_000060 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000390385.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:16,405 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:16,463 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:16,463 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:16,471 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:16,471 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:16,645 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:16,832 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:16,978 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:17,335 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:17,344 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:17,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:17,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:17,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:17,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:17,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:17,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:17,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:17,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:17,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:17,507 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:15000000+3000000
2019-02-25 16:05:17,545 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:17,545 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:17,545 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:17,546 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:17,546 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:17,553 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:17,572 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:17,572 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:17,691 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,692 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:17,698 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:17,700 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000390385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,702 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:17,706 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000005_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000091 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1550090358635_0074_01_000055 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000237025.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6391
Log Contents:
2019-02-25 16:05:16,401 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:16,456 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:16,456 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:16,464 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:16,464 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:16,633 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:16,818 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:16,962 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:17,322 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:17,332 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:17,354 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:17,354 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:17,354 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:17,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:17,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:17,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:17,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:17,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:17,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:17,489 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:9000000+3000000
2019-02-25 16:05:17,531 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:17,531 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:17,531 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:17,531 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:17,531 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:17,539 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:17,559 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:17,560 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:17,609 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,611 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:17,616 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:17,619 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000237025.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,620 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:17,624 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000003_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000065 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000767605.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:17,414 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:17,469 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:17,469 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:17,477 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:17,477 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:17,646 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:17,829 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:17,975 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:18,323 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:18,333 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:18,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:18,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:18,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:18,355 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:18,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:18,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:18,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:18,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:18,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:18,481 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:33000000+3000000
2019-02-25 16:05:18,520 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:18,521 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:18,521 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:18,521 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:18,521 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:18,528 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:18,547 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:18,547 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:18,631 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,632 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:18,638 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:18,640 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000767605.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,642 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:18,646 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000011_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000033 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900159185.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:04,903 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:04,957 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:04,957 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:04,965 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:04,965 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:05,134 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:05,324 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:05,477 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:05,867 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:05,877 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:05,897 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:05,898 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:05,898 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:05,898 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:05,898 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:05,898 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:05,898 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:05,898 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:05,898 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:06,035 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:90000000+3000000
2019-02-25 16:05:06,075 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:06,075 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:06,075 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:06,075 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:06,075 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:06,083 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:06,104 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:06,104 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:06,166 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:06,167 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:06,173 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:06,176 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,182 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:06,186 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000030_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000001 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:1703
Log Contents:
Feb 25, 2019 4:05:00 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class
Feb 25, 2019 4:05:00 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
Feb 25, 2019 4:05:00 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class
Feb 25, 2019 4:05:00 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.9 09/02/2011 11:17 AM'
Feb 25, 2019 4:05:00 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope "Singleton"
Feb 25, 2019 4:05:01 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope "Singleton"
Feb 25, 2019 4:05:01 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope "PerRequest"
log4j:WARN No appenders could be found for logger (org.apache.hadoop.ipc.Server).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:824786
Log Contents:
2019-02-25 16:04:59,221 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1550090358635_0074_000001
2019-02-25 16:04:59,368 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
2019-02-25 16:04:59,368 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 74 cluster_timestamp: 1550090358635 } attemptId: 1 } keyId: -1532799566)
2019-02-25 16:04:59,547 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
2019-02-25 16:04:59,548 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
2019-02-25 16:04:59,585 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:04:59,971 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is boa.io.BoaOutputCommitter
2019-02-25 16:05:00,075 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler
2019-02-25 16:05:00,076 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher
2019-02-25 16:05:00,076 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher
2019-02-25 16:05:00,077 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher
2019-02-25 16:05:00,077 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2019-02-25 16:05:00,078 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher
2019-02-25 16:05:00,078 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter
2019-02-25 16:05:00,079 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter
2019-02-25 16:05:00,106 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://r383.opa.bridges.psc.edu:8020]
2019-02-25 16:05:00,123 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://r383.opa.bridges.psc.edu:8020]
2019-02-25 16:05:00,138 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://r383.opa.bridges.psc.edu:8020]
2019-02-25 16:05:00,143 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
2019-02-25 16:05:00,171 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler
2019-02-25 16:05:00,230 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:00,274 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:00,274 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started
2019-02-25 16:05:00,280 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1550090358635_0074 to jobTokenSecretManager
2019-02-25 16:05:00,362 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1550090358635_0074 because: not enabled; too many maps; too much RAM;
2019-02-25 16:05:00,377 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1550090358635_0074 = 95535356. Number of splits = 32
2019-02-25 16:05:00,378 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1550090358635_0074 = 1
2019-02-25 16:05:00,378 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1550090358635_0074Job Transitioned from NEW to INITED
2019-02-25 16:05:00,379 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1550090358635_0074.
2019-02-25 16:05:00,401 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2019-02-25 16:05:00,408 INFO [Socket Reader #1 for port 42306] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 42306
2019-02-25 16:05:00,421 INFO [main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
2019-02-25 16:05:00,422 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-25 16:05:00,422 INFO [IPC Server listener on 42306] org.apache.hadoop.ipc.Server: IPC Server listener on 42306: starting
2019-02-25 16:05:00,422 INFO [main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at r385.pvt.bridges.psc.edu/10.4.217.133:42306
2019-02-25 16:05:00,473 INFO [main] org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-02-25 16:05:00,479 INFO [main] org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-25 16:05:00,482 INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
2019-02-25 16:05:00,486 INFO [main] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-25 16:05:00,489 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce
2019-02-25 16:05:00,489 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static
2019-02-25 16:05:00,491 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*
2019-02-25 16:05:00,491 INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2019-02-25 16:05:00,703 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2019-02-25 16:05:00,705 INFO [main] org.apache.hadoop.http.HttpServer2: Jetty bound to port 42947
2019-02-25 16:05:00,705 INFO [main] org.mortbay.log: jetty-6.1.26
2019-02-25 16:05:00,725 INFO [main] org.mortbay.log: Extract jar:file:/opt/packages/hadoop-testing/hadoop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/mapreduce to /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074/container_1550090358635_0074_01_000001/tmp/Jetty_0_0_0_0_42947_mapreduce____.dlo7np/webapp
2019-02-25 16:05:01,451 INFO [main] org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:42947
2019-02-25 16:05:01,451 INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Web app mapreduce started at 42947
2019-02-25 16:05:01,454 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2019-02-25 16:05:01,454 INFO [Socket Reader #1 for port 40283] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 40283
2019-02-25 16:05:01,456 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-25 16:05:01,457 INFO [IPC Server listener on 40283] org.apache.hadoop.ipc.Server: IPC Server listener on 40283: starting
2019-02-25 16:05:01,470 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
2019-02-25 16:05:01,471 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3
2019-02-25 16:05:01,471 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33
2019-02-25 16:05:01,496 INFO [main] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at r383.opa.bridges.psc.edu/10.4.117.131:8030
2019-02-25 16:05:01,551 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: maxContainerCapability: <memory:131072, vCores:128>
2019-02-25 16:05:01,551 INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: queue: default
2019-02-25 16:05:01,554 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
2019-02-25 16:05:01,555 INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: The thread pool initial size is 10
2019-02-25 16:05:01,556 INFO [main] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2019-02-25 16:05:01,561 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1550090358635_0074Job Transitioned from INITED to SETUP
2019-02-25 16:05:01,562 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP
2019-02-25 16:05:01,588 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1550090358635_0074Job Transitioned from SETUP to RUNNING
2019-02-25 16:05:01,600 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,601 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,604 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000000 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,604 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,604 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,604 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000001 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,604 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,604 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000002 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000003 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000004 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,605 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000005 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000006 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000007 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,607 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,607 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000008 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,607 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000009 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000010 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000011 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,608 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000012 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000013 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000014 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000015 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000016 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000017 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000018 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000019 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000020 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000021 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000022 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000023 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000024 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000025 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000026 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000027 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000028 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,615 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000029 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,615 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,615 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,615 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000030 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,615 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,615 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:01,615 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000031 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,615 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_r_000000 Task Transitioned from NEW to SCHEDULED
2019-02-25 16:05:01,617 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,617 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,617 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,617 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,617 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,617 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,617 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,617 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,619 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,620 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,620 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,620 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_r_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:01,620 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:<memory:5012, vCores:1>
2019-02-25 16:05:01,626 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1550090358635_0074, File: hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/hbagheri/.staging/job_1550090358635_0074/job_1550090358635_0074_1.jhist
2019-02-25 16:05:01,627 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: reduceResourceRequest:<memory:5012, vCores:1>
2019-02-25 16:05:02,555 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:32 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0
2019-02-25 16:05:02,597 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=4 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:522752, vCores:1> knownNMs=4
2019-02-25 16:05:02,598 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:522752, vCores:1>
2019-02-25 16:05:02,599 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:03,610 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 32
2019-02-25 16:05:03,612 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000002 to attempt_1550090358635_0074_m_000000_0
2019-02-25 16:05:03,614 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000003 to attempt_1550090358635_0074_m_000001_0
2019-02-25 16:05:03,614 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000004 to attempt_1550090358635_0074_m_000002_0
2019-02-25 16:05:03,614 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000005 to attempt_1550090358635_0074_m_000003_0
2019-02-25 16:05:03,614 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000006 to attempt_1550090358635_0074_m_000004_0
2019-02-25 16:05:03,615 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000007 to attempt_1550090358635_0074_m_000005_0
2019-02-25 16:05:03,615 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000008 to attempt_1550090358635_0074_m_000006_0
2019-02-25 16:05:03,615 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000009 to attempt_1550090358635_0074_m_000007_0
2019-02-25 16:05:03,615 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000010 to attempt_1550090358635_0074_m_000008_0
2019-02-25 16:05:03,615 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000011 to attempt_1550090358635_0074_m_000009_0
2019-02-25 16:05:03,616 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000012 to attempt_1550090358635_0074_m_000010_0
2019-02-25 16:05:03,616 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000013 to attempt_1550090358635_0074_m_000011_0
2019-02-25 16:05:03,616 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000014 to attempt_1550090358635_0074_m_000012_0
2019-02-25 16:05:03,616 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000015 to attempt_1550090358635_0074_m_000013_0
2019-02-25 16:05:03,616 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000016 to attempt_1550090358635_0074_m_000014_0
2019-02-25 16:05:03,616 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000017 to attempt_1550090358635_0074_m_000015_0
2019-02-25 16:05:03,617 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000018 to attempt_1550090358635_0074_m_000016_0
2019-02-25 16:05:03,617 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000019 to attempt_1550090358635_0074_m_000017_0
2019-02-25 16:05:03,617 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000020 to attempt_1550090358635_0074_m_000018_0
2019-02-25 16:05:03,617 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000021 to attempt_1550090358635_0074_m_000019_0
2019-02-25 16:05:03,617 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000022 to attempt_1550090358635_0074_m_000020_0
2019-02-25 16:05:03,617 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000023 to attempt_1550090358635_0074_m_000021_0
2019-02-25 16:05:03,617 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000024 to attempt_1550090358635_0074_m_000022_0
2019-02-25 16:05:03,617 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000025 to attempt_1550090358635_0074_m_000023_0
2019-02-25 16:05:03,618 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000026 to attempt_1550090358635_0074_m_000024_0
2019-02-25 16:05:03,618 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000027 to attempt_1550090358635_0074_m_000025_0
2019-02-25 16:05:03,618 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000029 to attempt_1550090358635_0074_m_000026_0
2019-02-25 16:05:03,618 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000030 to attempt_1550090358635_0074_m_000027_0
2019-02-25 16:05:03,618 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000031 to attempt_1550090358635_0074_m_000028_0
2019-02-25 16:05:03,619 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000032 to attempt_1550090358635_0074_m_000029_0
2019-02-25 16:05:03,619 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000033 to attempt_1550090358635_0074_m_000030_0
2019-02-25 16:05:03,619 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000034 to attempt_1550090358635_0074_m_000031_0
2019-02-25 16:05:03,619 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:361984, vCores:1>
2019-02-25 16:05:03,619 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:03,619 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:32 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:32 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:03,661 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/hbagheri/.staging/job_1550090358635_0074/job.jar
2019-02-25 16:05:03,678 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/hbagheri/.staging/job_1550090358635_0074/job.xml
2019-02-25 16:05:03,679 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container
2019-02-25 16:05:03,679 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1
2019-02-25 16:05:03,679 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData
2019-02-25 16:05:03,700 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,702 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,703 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,703 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,703 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,704 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,704 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,704 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,704 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,707 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,707 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,707 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,707 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,708 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,708 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,708 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,708 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,709 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,709 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,709 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,716 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,716 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,716 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,716 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,716 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,717 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,717 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,717 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:03,717 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:03,719 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000002 taskAttempt attempt_1550090358635_0074_m_000000_0
2019-02-25 16:05:03,719 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000003 taskAttempt attempt_1550090358635_0074_m_000001_0
2019-02-25 16:05:03,719 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000004 taskAttempt attempt_1550090358635_0074_m_000002_0
2019-02-25 16:05:03,720 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000005 taskAttempt attempt_1550090358635_0074_m_000003_0
2019-02-25 16:05:03,720 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000006 taskAttempt attempt_1550090358635_0074_m_000004_0
2019-02-25 16:05:03,720 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000007 taskAttempt attempt_1550090358635_0074_m_000005_0
2019-02-25 16:05:03,720 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000008 taskAttempt attempt_1550090358635_0074_m_000006_0
2019-02-25 16:05:03,720 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000009 taskAttempt attempt_1550090358635_0074_m_000007_0
2019-02-25 16:05:03,721 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000010 taskAttempt attempt_1550090358635_0074_m_000008_0
2019-02-25 16:05:03,721 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000011 taskAttempt attempt_1550090358635_0074_m_000009_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000001_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000007_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000006_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000003_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000008_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000000_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000009_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000004_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000002_0
2019-02-25 16:05:03,722 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000005_0
2019-02-25 16:05:03,723 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,740 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,741 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,742 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,744 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,744 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,746 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,746 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,747 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,748 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,782 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000001_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000002_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000000_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000008_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000005_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000007_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000009_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000006_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000004_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000003_0 : 13562
2019-02-25 16:05:03,782 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000012 taskAttempt attempt_1550090358635_0074_m_000010_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000013 taskAttempt attempt_1550090358635_0074_m_000011_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000010_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000014 taskAttempt attempt_1550090358635_0074_m_000012_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000011_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000021 taskAttempt attempt_1550090358635_0074_m_000019_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000020 taskAttempt attempt_1550090358635_0074_m_000018_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000019 taskAttempt attempt_1550090358635_0074_m_000017_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000017 taskAttempt attempt_1550090358635_0074_m_000015_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000016 taskAttempt attempt_1550090358635_0074_m_000014_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000015 taskAttempt attempt_1550090358635_0074_m_000013_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000018 taskAttempt attempt_1550090358635_0074_m_000016_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000013_0
2019-02-25 16:05:03,783 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000016_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000014_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000015_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000017_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000018_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000019_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000012_0
2019-02-25 16:05:03,782 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,783 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000009_0] using containerId: [container_1550090358635_0074_01_000011 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,783 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,784 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,784 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,785 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,786 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,787 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,787 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000000_0] using containerId: [container_1550090358635_0074_01_000002 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,787 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,787 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000002_0] using containerId: [container_1550090358635_0074_01_000004 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,787 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000010_0 : 13562
2019-02-25 16:05:03,787 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,787 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000008_0] using containerId: [container_1550090358635_0074_01_000010 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,788 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,788 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000005_0] using containerId: [container_1550090358635_0074_01_000007 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,788 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,788 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000001_0] using containerId: [container_1550090358635_0074_01_000003 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,788 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,788 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000003_0] using containerId: [container_1550090358635_0074_01_000005 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,789 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,789 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000019_0 : 13562
2019-02-25 16:05:03,789 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000007_0] using containerId: [container_1550090358635_0074_01_000009 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,789 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,789 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000022 taskAttempt attempt_1550090358635_0074_m_000020_0
2019-02-25 16:05:03,789 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000020_0
2019-02-25 16:05:03,789 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,790 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000006_0] using containerId: [container_1550090358635_0074_01_000008 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,790 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000012_0 : 13562
2019-02-25 16:05:03,790 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,790 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000004_0] using containerId: [container_1550090358635_0074_01_000006 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,790 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,790 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,790 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000018_0 : 13562
2019-02-25 16:05:03,790 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000009 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,791 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000000 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,792 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000010_0] using containerId: [container_1550090358635_0074_01_000012 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,792 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000017_0 : 13562
2019-02-25 16:05:03,792 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,792 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,792 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000002 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,792 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000008 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,792 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000005 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,792 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000001 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,792 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000003 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,792 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000019_0] using containerId: [container_1550090358635_0074_01_000021 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,792 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,793 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000007 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,793 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,793 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000012_0] using containerId: [container_1550090358635_0074_01_000014 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,793 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,793 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000006 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,793 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000004 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,793 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000018_0] using containerId: [container_1550090358635_0074_01_000020 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,793 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,793 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000017_0] using containerId: [container_1550090358635_0074_01_000019 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,793 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000015_0 : 13562
2019-02-25 16:05:03,793 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000023 taskAttempt attempt_1550090358635_0074_m_000021_0
2019-02-25 16:05:03,794 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000025 taskAttempt attempt_1550090358635_0074_m_000023_0
2019-02-25 16:05:03,793 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000024 taskAttempt attempt_1550090358635_0074_m_000022_0
2019-02-25 16:05:03,794 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000023_0
2019-02-25 16:05:03,794 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,794 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000021_0
2019-02-25 16:05:03,794 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000026 taskAttempt attempt_1550090358635_0074_m_000024_0
2019-02-25 16:05:03,796 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000024_0
2019-02-25 16:05:03,795 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,795 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000022_0
2019-02-25 16:05:03,797 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000010 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,797 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000019 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,797 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000012 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,797 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000018 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,797 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000015_0] using containerId: [container_1550090358635_0074_01_000017 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,797 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000027 taskAttempt attempt_1550090358635_0074_m_000025_0
2019-02-25 16:05:03,798 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000025_0
2019-02-25 16:05:03,798 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,798 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,798 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000014_0 : 13562
2019-02-25 16:05:03,798 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000017 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,798 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000015 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,798 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000014_0] using containerId: [container_1550090358635_0074_01_000016 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,799 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,799 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000016_0 : 13562
2019-02-25 16:05:03,799 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000014 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,799 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000016_0] using containerId: [container_1550090358635_0074_01_000018 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,799 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,799 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,799 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000016 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,799 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000013_0 : 13562
2019-02-25 16:05:03,799 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000013_0] using containerId: [container_1550090358635_0074_01_000015 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,801 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,801 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000013 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,801 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,801 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000011_0 : 13562
2019-02-25 16:05:03,802 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000011_0] using containerId: [container_1550090358635_0074_01_000013 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,802 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,802 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,802 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000011 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,802 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000029 taskAttempt attempt_1550090358635_0074_m_000026_0
2019-02-25 16:05:03,802 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000030 taskAttempt attempt_1550090358635_0074_m_000027_0
2019-02-25 16:05:03,802 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000031 taskAttempt attempt_1550090358635_0074_m_000028_0
2019-02-25 16:05:03,803 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000027_0
2019-02-25 16:05:03,803 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000028_0
2019-02-25 16:05:03,803 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:03,803 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000032 taskAttempt attempt_1550090358635_0074_m_000029_0
2019-02-25 16:05:03,802 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000026_0
2019-02-25 16:05:03,803 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000029_0
2019-02-25 16:05:03,803 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000020_0 : 13562
2019-02-25 16:05:03,803 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000020_0] using containerId: [container_1550090358635_0074_01_000022 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,803 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,803 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000020 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,803 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000033 taskAttempt attempt_1550090358635_0074_m_000030_0
2019-02-25 16:05:03,803 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:03,803 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000030_0
2019-02-25 16:05:03,804 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000022_0 : 13562
2019-02-25 16:05:03,805 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:03,805 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000024_0 : 13562
2019-02-25 16:05:03,805 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000022_0] using containerId: [container_1550090358635_0074_01_000024 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,805 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,805 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000021_0 : 13562
2019-02-25 16:05:03,805 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000024_0] using containerId: [container_1550090358635_0074_01_000026 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,806 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,806 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000022 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,806 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:03,806 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000021_0] using containerId: [container_1550090358635_0074_01_000023 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,806 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,807 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000024 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,807 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000021 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,807 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:03,808 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000023_0 : 13562
2019-02-25 16:05:03,808 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000034 taskAttempt attempt_1550090358635_0074_m_000031_0
2019-02-25 16:05:03,808 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000031_0
2019-02-25 16:05:03,808 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:03,808 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000023_0] using containerId: [container_1550090358635_0074_01_000025 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,808 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,809 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000025_0 : 13562
2019-02-25 16:05:03,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000023 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000025_0] using containerId: [container_1550090358635_0074_01_000027 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:03,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,810 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:03,810 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000025 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,810 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000026_0 : 13562
2019-02-25 16:05:03,810 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000026_0] using containerId: [container_1550090358635_0074_01_000029 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:03,810 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000029_0 : 13562
2019-02-25 16:05:03,810 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,810 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000026 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000029_0] using containerId: [container_1550090358635_0074_01_000032 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:03,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,811 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000028_0 : 13562
2019-02-25 16:05:03,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000029 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000028_0] using containerId: [container_1550090358635_0074_01_000031 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:03,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,812 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000028 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,812 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000027_0 : 13562
2019-02-25 16:05:03,812 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000027_0] using containerId: [container_1550090358635_0074_01_000030 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:03,813 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,813 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000027 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,814 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000031_0 : 13562
2019-02-25 16:05:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000031_0] using containerId: [container_1550090358635_0074_01_000034 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000031 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:03,814 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000030_0 : 13562
2019-02-25 16:05:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000030_0] using containerId: [container_1550090358635_0074_01_000033 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:03,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000030 Task Transitioned from SCHEDULED to RUNNING
2019-02-25 16:05:04,621 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=4 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:361984, vCores:1> knownNMs=4
2019-02-25 16:05:05,243 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:05,244 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:05,258 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000033 asked for a task
2019-02-25 16:05:05,258 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000033 given task: attempt_1550090358635_0074_m_000030_0
2019-02-25 16:05:05,259 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000029 asked for a task
2019-02-25 16:05:05,259 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000029 given task: attempt_1550090358635_0074_m_000026_0
2019-02-25 16:05:05,270 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:05,279 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000031 asked for a task
2019-02-25 16:05:05,279 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000031 given task: attempt_1550090358635_0074_m_000028_0
2019-02-25 16:05:05,283 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:05,292 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000030 asked for a task
2019-02-25 16:05:05,292 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000030 given task: attempt_1550090358635_0074_m_000027_0
2019-02-25 16:05:05,297 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:05,298 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:05,306 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000032 asked for a task
2019-02-25 16:05:05,306 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000032 given task: attempt_1550090358635_0074_m_000029_0
2019-02-25 16:05:05,307 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000034 asked for a task
2019-02-25 16:05:05,307 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000034 given task: attempt_1550090358635_0074_m_000031_0
2019-02-25 16:05:06,179 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000030_0 is : 0.0
2019-02-25 16:05:06,186 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000026_0 is : 0.0
2019-02-25 16:05:06,187 FATAL [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000030_0 - exited : java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,187 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_0: Error: java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,188 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_0: Error: java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,189 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:06,189 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000033 taskAttempt attempt_1550090358635_0074_m_000030_0
2019-02-25 16:05:06,189 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000030_0
2019-02-25 16:05:06,189 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:06,192 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000028_0 is : 0.0
2019-02-25 16:05:06,193 FATAL [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000026_0 - exited : java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,193 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_0: Error: java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,193 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_0: Error: java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,194 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:06,194 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000029 taskAttempt attempt_1550090358635_0074_m_000026_0
2019-02-25 16:05:06,194 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000026_0
2019-02-25 16:05:06,194 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:06,198 FATAL [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000028_0 - exited : java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,198 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_0: Error: java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,199 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_0: Error: java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,199 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:06,200 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000031 taskAttempt attempt_1550090358635_0074_m_000028_0
2019-02-25 16:05:06,200 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000028_0
2019-02-25 16:05:06,200 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:06,203 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:06,203 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:06,203 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:06,204 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:06,204 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:06,204 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:06,209 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000028_0
2019-02-25 16:05:06,209 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000030_0
2019-02-25 16:05:06,209 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000026_0
2019-02-25 16:05:06,210 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:06,210 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:06,210 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:06,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,216 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node r385.pvt.bridges.psc.edu
2019-02-25 16:05:06,217 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:06,217 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 2 failures on node r385.pvt.bridges.psc.edu
2019-02-25 16:05:06,217 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:06,217 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 3 failures on node r385.pvt.bridges.psc.edu
2019-02-25 16:05:06,217 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: Blacklisted host r385.pvt.bridges.psc.edu
2019-02-25 16:05:06,217 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:06,217 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000028_1 to list of failed maps
2019-02-25 16:05:06,217 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000030_1 to list of failed maps
2019-02-25 16:05:06,218 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000026_1 to list of failed maps
2019-02-25 16:05:06,233 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000031_0 is : 0.0
2019-02-25 16:05:06,239 FATAL [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000031_0 - exited : java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,239 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000031_0: Error: java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,239 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000031_0: Error: java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,240 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:06,240 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000034 taskAttempt attempt_1550090358635_0074_m_000031_0
2019-02-25 16:05:06,240 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000031_0
2019-02-25 16:05:06,240 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:06,244 INFO [IPC Server handler 9 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000029_0 is : 0.0
2019-02-25 16:05:06,244 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:06,245 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:06,246 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000031_0
2019-02-25 16:05:06,246 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:06,246 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,246 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,246 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:06,247 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000031_1 to list of failed maps
2019-02-25 16:05:06,249 FATAL [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000029_0 - exited : java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,249 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000029_0: Error: java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,250 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000029_0: Error: java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,250 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:06,250 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000032 taskAttempt attempt_1550090358635_0074_m_000029_0
2019-02-25 16:05:06,250 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000029_0
2019-02-25 16:05:06,251 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:06,254 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:06,254 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:06,255 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000029_0
2019-02-25 16:05:06,255 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:06,255 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,255 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,255 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:06,256 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000029_1 to list of failed maps
2019-02-25 16:05:06,256 INFO [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000027_0 is : 0.0
2019-02-25 16:05:06,261 FATAL [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000027_0 - exited : java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,261 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000027_0: Error: java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,262 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000027_0: Error: java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,262 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:06,262 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000030 taskAttempt attempt_1550090358635_0074_m_000027_0
2019-02-25 16:05:06,263 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000027_0
2019-02-25 16:05:06,263 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:06,265 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:06,265 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:06,266 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000027_0
2019-02-25 16:05:06,266 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:06,267 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,267 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:06,267 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:06,267 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000027_1 to list of failed maps
2019-02-25 16:05:06,623 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:6 ScheduledReds:0 AssignedMaps:32 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:32 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:06,629 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=0 finishedContainers=5 resourcelimit=<memory:387104, vCores:1> knownNMs=4
2019-02-25 16:05:06,629 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: Update the blacklist for application_1550090358635_0074: blacklistAdditions=1 blacklistRemovals=0
2019-02-25 16:05:06,629 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000033
2019-02-25 16:05:06,630 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000031
2019-02-25 16:05:06,630 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000029
2019-02-25 16:05:06,630 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000034
2019-02-25 16:05:06,630 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000032
2019-02-25 16:05:06,630 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:06,630 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:387104, vCores:1>
2019-02-25 16:05:06,630 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:06,630 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:06,630 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:6 ScheduledReds:0 AssignedMaps:27 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:32 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:06,630 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:06,630 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000031_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:06,630 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000029_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:07,632 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000030
2019-02-25 16:05:07,632 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 2
2019-02-25 16:05:07,632 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000027_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:07,633 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000035, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:07,633 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:07,633 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000035 to attempt_1550090358635_0074_m_000028_1
2019-02-25 16:05:07,633 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000037, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:07,633 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:07,633 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000037 to attempt_1550090358635_0074_m_000030_1
2019-02-25 16:05:07,633 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:377056, vCores:1>
2019-02-25 16:05:07,633 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:07,633 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:4 ScheduledReds:0 AssignedMaps:28 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:34 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:07,634 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:07,635 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:07,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:07,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:07,636 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000035 taskAttempt attempt_1550090358635_0074_m_000028_1
2019-02-25 16:05:07,636 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000037 taskAttempt attempt_1550090358635_0074_m_000030_1
2019-02-25 16:05:07,636 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000028_1
2019-02-25 16:05:07,636 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000030_1
2019-02-25 16:05:07,636 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:07,637 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:07,651 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000030_1 : 13562
2019-02-25 16:05:07,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000030_1] using containerId: [container_1550090358635_0074_01_000037 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:07,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:07,655 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000028_1 : 13562
2019-02-25 16:05:07,655 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000028_1] using containerId: [container_1550090358635_0074_01_000035 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:07,655 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:08,635 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=2 finishedContainers=0 resourcelimit=<memory:367008, vCores:1> knownNMs=4
2019-02-25 16:05:08,635 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 2
2019-02-25 16:05:08,636 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000038, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:08,636 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:08,636 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000038 to attempt_1550090358635_0074_m_000026_1
2019-02-25 16:05:08,636 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000039, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:08,636 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:08,636 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000039 to attempt_1550090358635_0074_m_000031_1
2019-02-25 16:05:08,636 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:367008, vCores:1>
2019-02-25 16:05:08,636 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:08,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:08,636 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:2 ScheduledReds:0 AssignedMaps:30 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:36 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:08,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:08,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:08,637 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:08,637 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000038 taskAttempt attempt_1550090358635_0074_m_000026_1
2019-02-25 16:05:08,637 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000039 taskAttempt attempt_1550090358635_0074_m_000031_1
2019-02-25 16:05:08,637 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000026_1
2019-02-25 16:05:08,637 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000031_1
2019-02-25 16:05:08,637 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:08,638 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:08,643 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000031_1 : 13562
2019-02-25 16:05:08,643 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000026_1 : 13562
2019-02-25 16:05:08,643 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000031_1] using containerId: [container_1550090358635_0074_01_000039 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:08,643 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:08,644 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000026_1] using containerId: [container_1550090358635_0074_01_000038 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:08,644 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:08,772 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:08,775 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:08,781 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000037 asked for a task
2019-02-25 16:05:08,781 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000037 given task: attempt_1550090358635_0074_m_000030_1
2019-02-25 16:05:08,784 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000035 asked for a task
2019-02-25 16:05:08,784 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000035 given task: attempt_1550090358635_0074_m_000028_1
2019-02-25 16:05:09,267 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,276 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000018 asked for a task
2019-02-25 16:05:09,277 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000018 given task: attempt_1550090358635_0074_m_000016_0
2019-02-25 16:05:09,285 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,295 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000009 asked for a task
2019-02-25 16:05:09,295 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000009 given task: attempt_1550090358635_0074_m_000007_0
2019-02-25 16:05:09,296 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,299 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,301 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,307 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000010 asked for a task
2019-02-25 16:05:09,307 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000010 given task: attempt_1550090358635_0074_m_000008_0
2019-02-25 16:05:09,308 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000027 asked for a task
2019-02-25 16:05:09,308 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000027 given task: attempt_1550090358635_0074_m_000025_0
2019-02-25 16:05:09,311 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000017 asked for a task
2019-02-25 16:05:09,311 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000017 given task: attempt_1550090358635_0074_m_000015_0
2019-02-25 16:05:09,327 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,331 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,333 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,337 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000002 asked for a task
2019-02-25 16:05:09,337 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000002 given task: attempt_1550090358635_0074_m_000000_0
2019-02-25 16:05:09,340 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000011 asked for a task
2019-02-25 16:05:09,340 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000011 given task: attempt_1550090358635_0074_m_000009_0
2019-02-25 16:05:09,344 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000004 asked for a task
2019-02-25 16:05:09,344 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000004 given task: attempt_1550090358635_0074_m_000002_0
2019-02-25 16:05:09,398 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,408 INFO [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000007 asked for a task
2019-02-25 16:05:09,408 INFO [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000007 given task: attempt_1550090358635_0074_m_000005_0
2019-02-25 16:05:09,426 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,453 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,456 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000003 asked for a task
2019-02-25 16:05:09,456 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000003 given task: attempt_1550090358635_0074_m_000001_0
2019-02-25 16:05:09,458 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,466 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,466 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000021 asked for a task
2019-02-25 16:05:09,466 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000021 given task: attempt_1550090358635_0074_m_000019_0
2019-02-25 16:05:09,476 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000020 asked for a task
2019-02-25 16:05:09,476 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000020 given task: attempt_1550090358635_0074_m_000018_0
2019-02-25 16:05:09,479 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000023 asked for a task
2019-02-25 16:05:09,479 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000023 given task: attempt_1550090358635_0074_m_000021_0
2019-02-25 16:05:09,486 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,497 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,501 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000022 asked for a task
2019-02-25 16:05:09,501 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000022 given task: attempt_1550090358635_0074_m_000020_0
2019-02-25 16:05:09,503 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,509 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,514 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000014 asked for a task
2019-02-25 16:05:09,514 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000014 given task: attempt_1550090358635_0074_m_000012_0
2019-02-25 16:05:09,515 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000006 asked for a task
2019-02-25 16:05:09,515 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000006 given task: attempt_1550090358635_0074_m_000004_0
2019-02-25 16:05:09,519 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,520 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000008 asked for a task
2019-02-25 16:05:09,520 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000008 given task: attempt_1550090358635_0074_m_000006_0
2019-02-25 16:05:09,523 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,536 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000005 asked for a task
2019-02-25 16:05:09,537 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000005 given task: attempt_1550090358635_0074_m_000003_0
2019-02-25 16:05:09,545 INFO [IPC Server handler 9 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000024 asked for a task
2019-02-25 16:05:09,545 INFO [IPC Server handler 9 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000024 given task: attempt_1550090358635_0074_m_000022_0
2019-02-25 16:05:09,575 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,600 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000019 asked for a task
2019-02-25 16:05:09,600 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000019 given task: attempt_1550090358635_0074_m_000017_0
2019-02-25 16:05:09,616 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,637 INFO [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000013 asked for a task
2019-02-25 16:05:09,637 INFO [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000013 given task: attempt_1550090358635_0074_m_000011_0
2019-02-25 16:05:09,638 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=2 finishedContainers=0 resourcelimit=<memory:356960, vCores:1> knownNMs=4
2019-02-25 16:05:09,638 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 2
2019-02-25 16:05:09,638 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000040, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:09,638 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:09,638 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000040 to attempt_1550090358635_0074_m_000029_1
2019-02-25 16:05:09,639 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000041, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:09,639 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:09,639 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000041 to attempt_1550090358635_0074_m_000027_1
2019-02-25 16:05:09,639 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:356960, vCores:1>
2019-02-25 16:05:09,639 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:09,639 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:32 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:38 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:09,639 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:09,639 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:09,639 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:09,639 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:09,640 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000040 taskAttempt attempt_1550090358635_0074_m_000029_1
2019-02-25 16:05:09,640 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000041 taskAttempt attempt_1550090358635_0074_m_000027_1
2019-02-25 16:05:09,640 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000029_1
2019-02-25 16:05:09,640 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000027_1
2019-02-25 16:05:09,640 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:09,641 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:09,644 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,645 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000027_1 : 13562
2019-02-25 16:05:09,645 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000027_1] using containerId: [container_1550090358635_0074_01_000041 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:09,645 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:09,646 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000029_1 : 13562
2019-02-25 16:05:09,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000029_1] using containerId: [container_1550090358635_0074_01_000040 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:09,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:09,656 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,665 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000039 asked for a task
2019-02-25 16:05:09,665 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000039 given task: attempt_1550090358635_0074_m_000031_1
2019-02-25 16:05:09,673 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,675 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000028_1 is : 0.0
2019-02-25 16:05:09,680 FATAL [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000028_1 - exited : java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:09,680 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_1: Error: java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:09,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_1: Error: java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:09,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:09,682 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000035 taskAttempt attempt_1550090358635_0074_m_000028_1
2019-02-25 16:05:09,682 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000030_1 is : 0.0
2019-02-25 16:05:09,683 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000028_1
2019-02-25 16:05:09,683 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:09,684 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000038 asked for a task
2019-02-25 16:05:09,684 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000038 given task: attempt_1550090358635_0074_m_000026_1
2019-02-25 16:05:09,684 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000025 asked for a task
2019-02-25 16:05:09,684 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000025 given task: attempt_1550090358635_0074_m_000023_0
2019-02-25 16:05:09,688 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:09,688 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:09,689 FATAL [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000030_1 - exited : java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:09,689 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_1: Error: java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:09,690 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_1: Error: java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:09,690 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000028_1
2019-02-25 16:05:09,691 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:09,691 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:09,691 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000037 taskAttempt attempt_1550090358635_0074_m_000030_1
2019-02-25 16:05:09,691 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:09,691 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000030_1
2019-02-25 16:05:09,691 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:09,692 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:09,692 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node r389.pvt.bridges.psc.edu
2019-02-25 16:05:09,692 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:09,692 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000028_2 to list of failed maps
2019-02-25 16:05:09,695 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:09,695 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:09,696 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000030_1
2019-02-25 16:05:09,696 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:09,697 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:09,697 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:09,697 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node r386.pvt.bridges.psc.edu
2019-02-25 16:05:09,697 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:09,697 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000030_2 to list of failed maps
2019-02-25 16:05:09,699 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,709 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000015 asked for a task
2019-02-25 16:05:09,709 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000015 given task: attempt_1550090358635_0074_m_000013_0
2019-02-25 16:05:09,724 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,737 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000016 asked for a task
2019-02-25 16:05:09,737 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000016 given task: attempt_1550090358635_0074_m_000014_0
2019-02-25 16:05:09,775 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,798 INFO [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000012 asked for a task
2019-02-25 16:05:09,798 INFO [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000012 given task: attempt_1550090358635_0074_m_000010_0
2019-02-25 16:05:09,887 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:09,923 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000026 asked for a task
2019-02-25 16:05:09,923 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000026 given task: attempt_1550090358635_0074_m_000024_0
2019-02-25 16:05:10,625 INFO [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000026_1 is : 0.0
2019-02-25 16:05:10,632 FATAL [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000026_1 - exited : java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:10,632 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_1: Error: java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:10,633 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_1: Error: java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:10,634 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:10,634 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000038 taskAttempt attempt_1550090358635_0074_m_000026_1
2019-02-25 16:05:10,634 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000026_1
2019-02-25 16:05:10,634 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:10,635 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:10,638 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:10,638 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:10,639 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:2 ScheduledReds:0 AssignedMaps:32 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:38 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:10,640 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000026_1
2019-02-25 16:05:10,640 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:10,640 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:10,640 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:10,640 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:10,641 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=2 finishedContainers=2 resourcelimit=<memory:361984, vCores:1> knownNMs=4
2019-02-25 16:05:10,641 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000037
2019-02-25 16:05:10,641 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000035
2019-02-25 16:05:10,641 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 2
2019-02-25 16:05:10,641 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:10,641 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000042, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:10,641 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:10,641 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:10,642 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000042 to attempt_1550090358635_0074_m_000028_2
2019-02-25 16:05:10,642 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000043, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:10,642 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:10,642 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000043 to attempt_1550090358635_0074_m_000030_2
2019-02-25 16:05:10,642 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:10,642 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:361984, vCores:1>
2019-02-25 16:05:10,642 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:10,642 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:32 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:40 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:10,642 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 2 failures on node r389.pvt.bridges.psc.edu
2019-02-25 16:05:10,642 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000026_2 to list of failed maps
2019-02-25 16:05:10,642 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:10,643 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:10,643 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000041 asked for a task
2019-02-25 16:05:10,643 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000041 given task: attempt_1550090358635_0074_m_000027_1
2019-02-25 16:05:10,643 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:10,644 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000042 taskAttempt attempt_1550090358635_0074_m_000028_2
2019-02-25 16:05:10,644 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000043 taskAttempt attempt_1550090358635_0074_m_000030_2
2019-02-25 16:05:10,644 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000028_2
2019-02-25 16:05:10,644 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000030_2
2019-02-25 16:05:10,644 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:10,645 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:10,650 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000028_2 : 13562
2019-02-25 16:05:10,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000028_2] using containerId: [container_1550090358635_0074_01_000042 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:10,650 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000030_2 : 13562
2019-02-25 16:05:10,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:10,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000030_2] using containerId: [container_1550090358635_0074_01_000043 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:10,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:10,657 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:10,665 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000040 asked for a task
2019-02-25 16:05:10,665 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000040 given task: attempt_1550090358635_0074_m_000029_1
2019-02-25 16:05:10,688 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000031_1 is : 0.0
2019-02-25 16:05:10,693 FATAL [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000031_1 - exited : java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:10,694 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000031_1: Error: java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:10,694 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000031_1: Error: java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:10,696 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:10,696 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000039 taskAttempt attempt_1550090358635_0074_m_000031_1
2019-02-25 16:05:10,697 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000031_1
2019-02-25 16:05:10,697 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:10,701 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:10,701 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:10,702 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000031_1
2019-02-25 16:05:10,702 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:10,703 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:10,703 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:10,703 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 2 failures on node r386.pvt.bridges.psc.edu
2019-02-25 16:05:10,703 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:10,703 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000031_2 to list of failed maps
2019-02-25 16:05:11,286 INFO [IPC Server handler 23 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000016_0 is : 0.0
2019-02-25 16:05:11,309 FATAL [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000016_0 - exited : java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,309 INFO [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000016_0: Error: java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,309 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000016_0: Error: java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,310 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,310 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000018 taskAttempt attempt_1550090358635_0074_m_000016_0
2019-02-25 16:05:11,311 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000016_0
2019-02-25 16:05:11,311 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,317 INFO [IPC Server handler 22 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000009_0 is : 0.0
2019-02-25 16:05:11,318 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,318 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,319 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000016_0
2019-02-25 16:05:11,320 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,320 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,320 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,320 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node r388.pvt.bridges.psc.edu
2019-02-25 16:05:11,320 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,320 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000016_1 to list of failed maps
2019-02-25 16:05:11,330 FATAL [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000009_0 - exited : java.io.IOException: map failure for key 'GCF_000691865.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,330 INFO [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000009_0: Error: java.io.IOException: map failure for key 'GCF_000691865.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,331 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000009_0: Error: java.io.IOException: map failure for key 'GCF_000691865.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,332 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,332 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000011 taskAttempt attempt_1550090358635_0074_m_000009_0
2019-02-25 16:05:11,332 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000009_0
2019-02-25 16:05:11,333 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,348 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,348 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,349 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000009_0
2019-02-25 16:05:11,349 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,350 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,350 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,350 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 2 failures on node r388.pvt.bridges.psc.edu
2019-02-25 16:05:11,350 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,350 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000009_1 to list of failed maps
2019-02-25 16:05:11,460 INFO [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000015_0 is : 0.0
2019-02-25 16:05:11,467 FATAL [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000015_0 - exited : java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,467 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000015_0: Error: java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,468 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000015_0: Error: java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,468 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,469 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000017 taskAttempt attempt_1550090358635_0074_m_000015_0
2019-02-25 16:05:11,469 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000015_0
2019-02-25 16:05:11,469 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,472 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,473 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,474 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000015_0
2019-02-25 16:05:11,474 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,474 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,474 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,475 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 3 failures on node r388.pvt.bridges.psc.edu
2019-02-25 16:05:11,475 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,475 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: Blacklisted host r388.pvt.bridges.psc.edu
2019-02-25 16:05:11,475 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000015_1 to list of failed maps
2019-02-25 16:05:11,501 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000019_0 is : 0.0
2019-02-25 16:05:11,508 FATAL [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000019_0 - exited : java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,508 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000019_0: Error: java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,509 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000019_0: Error: java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,509 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,509 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000021 taskAttempt attempt_1550090358635_0074_m_000019_0
2019-02-25 16:05:11,510 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000019_0
2019-02-25 16:05:11,510 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,517 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000021_0 is : 0.0
2019-02-25 16:05:11,518 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,519 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,520 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000019_0
2019-02-25 16:05:11,520 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,520 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,520 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,520 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,520 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000019_1 to list of failed maps
2019-02-25 16:05:11,529 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000027_1 is : 0.0
2019-02-25 16:05:11,534 FATAL [IPC Server handler 9 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000027_1 - exited : java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,535 INFO [IPC Server handler 9 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000027_1: Error: java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000027_1: Error: java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,535 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000041 taskAttempt attempt_1550090358635_0074_m_000027_1
2019-02-25 16:05:11,536 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000027_1
2019-02-25 16:05:11,536 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:11,539 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,539 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,541 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000027_1
2019-02-25 16:05:11,541 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000025_0 is : 0.0
2019-02-25 16:05:11,541 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,541 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,541 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,542 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 3 failures on node r386.pvt.bridges.psc.edu
2019-02-25 16:05:11,542 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: Blacklisted host r386.pvt.bridges.psc.edu
2019-02-25 16:05:11,542 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,542 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000027_2 to list of failed maps
2019-02-25 16:05:11,549 FATAL [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000021_0 - exited : java.io.IOException: map failure for key 'GCF_002155895.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,549 INFO [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000021_0: Error: java.io.IOException: map failure for key 'GCF_002155895.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,549 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000021_0: Error: java.io.IOException: map failure for key 'GCF_002155895.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,550 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,550 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000023 taskAttempt attempt_1550090358635_0074_m_000021_0
2019-02-25 16:05:11,550 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000021_0
2019-02-25 16:05:11,550 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,558 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000029_1 is : 0.0
2019-02-25 16:05:11,559 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,559 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,560 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000021_0
2019-02-25 16:05:11,560 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,560 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,560 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,561 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,561 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000021_1 to list of failed maps
2019-02-25 16:05:11,562 FATAL [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000025_0 - exited : java.io.IOException: map failure for key 'GCF_003062915.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,562 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000025_0: Error: java.io.IOException: map failure for key 'GCF_003062915.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,562 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000025_0: Error: java.io.IOException: map failure for key 'GCF_003062915.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,563 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,563 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000027 taskAttempt attempt_1550090358635_0074_m_000025_0
2019-02-25 16:05:11,563 FATAL [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000029_1 - exited : java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,563 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000025_0
2019-02-25 16:05:11,563 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000029_1: Error: java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,564 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,564 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000029_1: Error: java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,564 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,564 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000040 taskAttempt attempt_1550090358635_0074_m_000029_1
2019-02-25 16:05:11,565 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000029_1
2019-02-25 16:05:11,565 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:11,568 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,568 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,568 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,568 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,569 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000025_0
2019-02-25 16:05:11,569 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000029_1
2019-02-25 16:05:11,569 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,569 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,570 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,570 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,570 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,570 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,570 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,570 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 3 failures on node r389.pvt.bridges.psc.edu
2019-02-25 16:05:11,570 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,570 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: Blacklisted host r389.pvt.bridges.psc.edu
2019-02-25 16:05:11,571 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000025_1 to list of failed maps
2019-02-25 16:05:11,571 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000029_2 to list of failed maps
2019-02-25 16:05:11,571 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000007_0 is : 0.0
2019-02-25 16:05:11,580 FATAL [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000007_0 - exited : java.io.IOException: map failure for key 'GCF_000517545.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,580 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000007_0: Error: java.io.IOException: map failure for key 'GCF_000517545.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,581 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000007_0: Error: java.io.IOException: map failure for key 'GCF_000517545.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,581 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,581 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000009 taskAttempt attempt_1550090358635_0074_m_000007_0
2019-02-25 16:05:11,582 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000007_0
2019-02-25 16:05:11,582 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,586 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,586 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,587 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000007_0
2019-02-25 16:05:11,587 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,587 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,587 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,587 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,587 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000007_1 to list of failed maps
2019-02-25 16:05:11,588 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000003_0 is : 0.0
2019-02-25 16:05:11,593 FATAL [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000003_0 - exited : java.io.IOException: map failure for key 'GCF_000237025.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,593 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000003_0: Error: java.io.IOException: map failure for key 'GCF_000237025.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,594 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000003_0: Error: java.io.IOException: map failure for key 'GCF_000237025.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,594 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,594 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000005 taskAttempt attempt_1550090358635_0074_m_000003_0
2019-02-25 16:05:11,594 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000003_0
2019-02-25 16:05:11,594 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,597 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000000_0 is : 0.0
2019-02-25 16:05:11,597 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,597 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,598 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000003_0
2019-02-25 16:05:11,599 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,599 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,599 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,599 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,599 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000003_1 to list of failed maps
2019-02-25 16:05:11,607 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000004_0 is : 0.0
2019-02-25 16:05:11,615 INFO [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000008_0 is : 0.0
2019-02-25 16:05:11,615 FATAL [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000000_0 - exited : java.io.IOException: map failure for key 'GCF_000001215.4'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,615 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000000_0: Error: java.io.IOException: map failure for key 'GCF_000001215.4'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,615 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000000_0: Error: java.io.IOException: map failure for key 'GCF_000001215.4'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,616 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,616 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000002 taskAttempt attempt_1550090358635_0074_m_000000_0
2019-02-25 16:05:11,616 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000000_0
2019-02-25 16:05:11,616 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,621 INFO [IPC Server handler 23 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000022_0 is : 0.0
2019-02-25 16:05:11,623 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,623 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,623 FATAL [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000008_0 - exited : java.io.IOException: map failure for key 'GCF_000622325.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,623 INFO [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000008_0: Error: java.io.IOException: map failure for key 'GCF_000622325.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,623 FATAL [IPC Server handler 22 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000004_0 - exited : java.io.IOException: map failure for key 'GCF_000323305.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,624 INFO [IPC Server handler 22 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000004_0: Error: java.io.IOException: map failure for key 'GCF_000323305.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,624 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000000_0
2019-02-25 16:05:11,624 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000008_0: Error: java.io.IOException: map failure for key 'GCF_000622325.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,624 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,624 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000004_0: Error: java.io.IOException: map failure for key 'GCF_000323305.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,625 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000010 taskAttempt attempt_1550090358635_0074_m_000008_0
2019-02-25 16:05:11,625 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000008_0
2019-02-25 16:05:11,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,625 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,625 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000006 taskAttempt attempt_1550090358635_0074_m_000004_0
2019-02-25 16:05:11,625 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000004_0
2019-02-25 16:05:11,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,626 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000000_1 to list of failed maps
2019-02-25 16:05:11,626 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,628 FATAL [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000022_0 - exited : java.io.IOException: map failure for key 'GCF_002289615.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,628 INFO [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000022_0: Error: java.io.IOException: map failure for key 'GCF_002289615.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,628 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000022_0: Error: java.io.IOException: map failure for key 'GCF_002289615.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,629 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,629 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000024 taskAttempt attempt_1550090358635_0074_m_000022_0
2019-02-25 16:05:11,629 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000022_0
2019-02-25 16:05:11,629 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,634 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,634 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,634 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,634 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,634 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,634 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,635 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000004_0
2019-02-25 16:05:11,635 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000008_0
2019-02-25 16:05:11,635 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000022_0
2019-02-25 16:05:11,635 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,635 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,637 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,637 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,637 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,637 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,637 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,637 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000004_1 to list of failed maps
2019-02-25 16:05:11,637 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000008_1 to list of failed maps
2019-02-25 16:05:11,637 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000022_1 to list of failed maps
2019-02-25 16:05:11,642 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:16 ScheduledReds:0 AssignedMaps:32 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:40 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:11,645 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=2 finishedContainers=8 resourcelimit=<memory:392128, vCores:1> knownNMs=4
2019-02-25 16:05:11,645 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: Update the blacklist for application_1550090358635_0074: blacklistAdditions=3 blacklistRemovals=0
2019-02-25 16:05:11,645 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: Ignore blacklisting set to true. Known: 4, Blacklisted: 4, 100%
2019-02-25 16:05:11,645 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000039
2019-02-25 16:05:11,645 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000041
2019-02-25 16:05:11,645 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000018
2019-02-25 16:05:11,645 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000031_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:11,645 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000011
2019-02-25 16:05:11,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000027_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000017
2019-02-25 16:05:11,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000016_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000021
2019-02-25 16:05:11,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000009_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000038
2019-02-25 16:05:11,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000015_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000040
2019-02-25 16:05:11,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000019_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 2
2019-02-25 16:05:11,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:11,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000029_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000044, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000044 to attempt_1550090358635_0074_m_000026_2
2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000045, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000045 to attempt_1550090358635_0074_m_000031_2
2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:392128, vCores:1>
2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:11,646 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,646 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:14 ScheduledReds:0 AssignedMaps:26 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:42 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:11,647 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:11,647 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,647 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:11,647 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000044 taskAttempt attempt_1550090358635_0074_m_000026_2
2019-02-25 16:05:11,647 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000045 taskAttempt attempt_1550090358635_0074_m_000031_2
2019-02-25 16:05:11,647 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000026_2
2019-02-25 16:05:11,647 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000031_2
2019-02-25 16:05:11,647 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:11,648 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:11,651 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000026_2 : 13562
2019-02-25 16:05:11,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000026_2] using containerId: [container_1550090358635_0074_01_000044 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:11,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:11,652 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000031_2 : 13562
2019-02-25 16:05:11,652 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000031_2] using containerId: [container_1550090358635_0074_01_000045 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:11,652 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:11,666 INFO [IPC Server handler 29 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000005_0 is : 0.0
2019-02-25 16:05:11,672 FATAL [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000005_0 - exited : java.io.IOException: map failure for key 'GCF_000390385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,672 INFO [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000005_0: Error: java.io.IOException: map failure for key 'GCF_000390385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000005_0: Error: java.io.IOException: map failure for key 'GCF_000390385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,672 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000007 taskAttempt attempt_1550090358635_0074_m_000005_0
2019-02-25 16:05:11,672 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000005_0
2019-02-25 16:05:11,672 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,686 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,686 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,687 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000005_0
2019-02-25 16:05:11,687 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,687 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,687 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,687 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,687 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000005_1 to list of failed maps
2019-02-25 16:05:11,693 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:11,696 INFO [IPC Server handler 24 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000014_0 is : 0.0
2019-02-25 16:05:11,699 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:11,702 INFO [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000043 asked for a task
2019-02-25 16:05:11,702 INFO [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000043 given task: attempt_1550090358635_0074_m_000030_2
2019-02-25 16:05:11,702 FATAL [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000014_0 - exited : java.io.IOException: map failure for key 'GCF_001218505.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,702 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000014_0: Error: java.io.IOException: map failure for key 'GCF_001218505.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,703 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000014_0: Error: java.io.IOException: map failure for key 'GCF_001218505.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,703 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,703 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000016 taskAttempt attempt_1550090358635_0074_m_000014_0
2019-02-25 16:05:11,703 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000014_0
2019-02-25 16:05:11,704 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,708 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000042 asked for a task
2019-02-25 16:05:11,708 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000042 given task: attempt_1550090358635_0074_m_000028_2
2019-02-25 16:05:11,709 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,710 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,710 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000014_0
2019-02-25 16:05:11,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,711 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000014_1 to list of failed maps
2019-02-25 16:05:11,715 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000020_0 is : 0.0
2019-02-25 16:05:11,722 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000001_0 is : 0.0
2019-02-25 16:05:11,722 FATAL [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000020_0 - exited : java.io.IOException: map failure for key 'GCF_002007485.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,722 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000020_0: Error: java.io.IOException: map failure for key 'GCF_002007485.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,722 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000020_0: Error: java.io.IOException: map failure for key 'GCF_002007485.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,722 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,722 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000022 taskAttempt attempt_1550090358635_0074_m_000020_0
2019-02-25 16:05:11,722 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000020_0
2019-02-25 16:05:11,722 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,727 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,727 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,728 FATAL [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000001_0 - exited : java.io.IOException: map failure for key 'GCF_000146835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,728 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000001_0: Error: java.io.IOException: map failure for key 'GCF_000146835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,728 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000020_0
2019-02-25 16:05:11,729 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,729 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000001_0: Error: java.io.IOException: map failure for key 'GCF_000146835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,729 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,729 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,729 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,729 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,729 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000003 taskAttempt attempt_1550090358635_0074_m_000001_0
2019-02-25 16:05:11,729 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000001_0
2019-02-25 16:05:11,729 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000020_1 to list of failed maps
2019-02-25 16:05:11,729 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,732 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,733 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,733 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000001_0
2019-02-25 16:05:11,733 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,734 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,734 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,734 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,734 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000001_1 to list of failed maps
2019-02-25 16:05:11,740 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000013_0 is : 0.0
2019-02-25 16:05:11,746 FATAL [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000013_0 - exited : java.io.IOException: map failure for key 'GCF_001083795.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,746 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000013_0: Error: java.io.IOException: map failure for key 'GCF_001083795.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,747 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000013_0: Error: java.io.IOException: map failure for key 'GCF_001083795.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,747 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,747 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000015 taskAttempt attempt_1550090358635_0074_m_000013_0
2019-02-25 16:05:11,747 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000013_0
2019-02-25 16:05:11,747 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,749 INFO [IPC Server handler 9 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000011_0 is : 0.0
2019-02-25 16:05:11,750 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,750 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,751 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000013_0
2019-02-25 16:05:11,751 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,751 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,751 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,751 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,752 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000013_1 to list of failed maps
2019-02-25 16:05:11,754 FATAL [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000011_0 - exited : java.io.IOException: map failure for key 'GCF_000767605.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,754 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000011_0: Error: java.io.IOException: map failure for key 'GCF_000767605.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,754 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000011_0: Error: java.io.IOException: map failure for key 'GCF_000767605.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,754 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,755 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000013 taskAttempt attempt_1550090358635_0074_m_000011_0
2019-02-25 16:05:11,755 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000011_0
2019-02-25 16:05:11,755 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,759 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,759 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,760 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000011_0
2019-02-25 16:05:11,760 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,760 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,760 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,760 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,760 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000011_1 to list of failed maps
2019-02-25 16:05:11,763 INFO [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000023_0 is : 0.0
2019-02-25 16:05:11,765 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000012_0 is : 0.0
2019-02-25 16:05:11,768 FATAL [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000023_0 - exited : java.io.IOException: map failure for key 'GCF_002708555.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,768 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000023_0: Error: java.io.IOException: map failure for key 'GCF_002708555.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,769 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000023_0: Error: java.io.IOException: map failure for key 'GCF_002708555.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,769 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,769 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000025 taskAttempt attempt_1550090358635_0074_m_000023_0
2019-02-25 16:05:11,769 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000023_0
2019-02-25 16:05:11,769 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,770 FATAL [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000012_0 - exited : java.io.IOException: map failure for key 'GCF_000935645.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,770 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000012_0: Error: java.io.IOException: map failure for key 'GCF_000935645.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,771 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000012_0: Error: java.io.IOException: map failure for key 'GCF_000935645.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,771 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,771 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000014 taskAttempt attempt_1550090358635_0074_m_000012_0
2019-02-25 16:05:11,771 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000012_0
2019-02-25 16:05:11,771 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,772 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,772 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,773 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000023_0
2019-02-25 16:05:11,773 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,773 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,773 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,773 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,773 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,774 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000023_1 to list of failed maps
2019-02-25 16:05:11,774 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,774 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000002_0 is : 0.0
2019-02-25 16:05:11,775 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000012_0
2019-02-25 16:05:11,775 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,775 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,775 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,775 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,775 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000012_1 to list of failed maps
2019-02-25 16:05:11,779 FATAL [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000002_0 - exited : java.io.IOException: map failure for key 'GCF_000208635.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,779 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000002_0: Error: java.io.IOException: map failure for key 'GCF_000208635.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,780 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000002_0: Error: java.io.IOException: map failure for key 'GCF_000208635.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,780 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,780 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000004 taskAttempt attempt_1550090358635_0074_m_000002_0
2019-02-25 16:05:11,780 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000002_0
2019-02-25 16:05:11,780 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,782 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,783 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,783 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000002_0
2019-02-25 16:05:11,783 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,784 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,784 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,784 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,784 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000002_1 to list of failed maps
2019-02-25 16:05:11,799 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000010_0 is : 0.0
2019-02-25 16:05:11,804 FATAL [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000010_0 - exited : java.io.IOException: map failure for key 'GCF_000708245.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,804 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000010_0: Error: java.io.IOException: map failure for key 'GCF_000708245.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,805 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000010_0: Error: java.io.IOException: map failure for key 'GCF_000708245.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,805 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,805 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000012 taskAttempt attempt_1550090358635_0074_m_000010_0
2019-02-25 16:05:11,805 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000010_0
2019-02-25 16:05:11,805 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,808 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,808 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,809 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000024_0 is : 0.0
2019-02-25 16:05:11,809 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000010_0
2019-02-25 16:05:11,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,809 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,809 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000010_1 to list of failed maps
2019-02-25 16:05:11,814 FATAL [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000024_0 - exited : java.io.IOException: map failure for key 'GCF_002901215.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,814 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000024_0: Error: java.io.IOException: map failure for key 'GCF_002901215.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000024_0: Error: java.io.IOException: map failure for key 'GCF_002901215.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,815 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000026 taskAttempt attempt_1550090358635_0074_m_000024_0
2019-02-25 16:05:11,815 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000024_0
2019-02-25 16:05:11,815 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,817 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,817 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,818 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000024_0
2019-02-25 16:05:11,818 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,818 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,818 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,818 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,818 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000024_1 to list of failed maps
2019-02-25 16:05:11,819 INFO [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000018_0 is : 0.0
2019-02-25 16:05:11,820 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000017_0 is : 0.0
2019-02-25 16:05:11,824 FATAL [IPC Server handler 23 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000018_0 - exited : java.io.IOException: map failure for key 'GCF_001682715.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,824 INFO [IPC Server handler 23 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000018_0: Error: java.io.IOException: map failure for key 'GCF_001682715.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,824 FATAL [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000017_0 - exited : java.io.IOException: map failure for key 'GCF_001574785.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,825 INFO [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000017_0: Error: java.io.IOException: map failure for key 'GCF_001574785.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,825 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000018_0: Error: java.io.IOException: map failure for key 'GCF_001682715.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,825 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,825 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000017_0: Error: java.io.IOException: map failure for key 'GCF_001574785.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,825 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,825 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000020 taskAttempt attempt_1550090358635_0074_m_000018_0
2019-02-25 16:05:11,825 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000019 taskAttempt attempt_1550090358635_0074_m_000017_0
2019-02-25 16:05:11,825 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000018_0
2019-02-25 16:05:11,825 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000017_0
2019-02-25 16:05:11,825 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,826 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,828 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,828 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,828 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,828 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,829 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000018_0
2019-02-25 16:05:11,829 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000017_0
2019-02-25 16:05:11,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,829 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,830 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000018_1 to list of failed maps
2019-02-25 16:05:11,830 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000017_1 to list of failed maps
2019-02-25 16:05:11,868 INFO [IPC Server handler 22 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000006_0 is : 0.0
2019-02-25 16:05:11,873 FATAL [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000006_0 - exited : java.io.IOException: map failure for key 'GCF_000457385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,873 INFO [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000006_0: Error: java.io.IOException: map failure for key 'GCF_000457385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,874 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000006_0: Error: java.io.IOException: map failure for key 'GCF_000457385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,874 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:11,874 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000008 taskAttempt attempt_1550090358635_0074_m_000006_0
2019-02-25 16:05:11,874 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000006_0
2019-02-25 16:05:11,874 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:11,876 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:11,876 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:11,877 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000006_0
2019-02-25 16:05:11,877 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:11,878 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,878 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:11,878 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:11,878 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000006_1 to list of failed maps
2019-02-25 16:05:12,571 INFO [IPC Server handler 29 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000028_2 is : 0.0
2019-02-25 16:05:12,576 FATAL [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000028_2 - exited : java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:12,576 INFO [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_2: Error: java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:12,576 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_2: Error: java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:12,577 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:12,577 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000042 taskAttempt attempt_1550090358635_0074_m_000028_2
2019-02-25 16:05:12,577 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000028_2
2019-02-25 16:05:12,577 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:12,580 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:12,580 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:12,581 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000028_2
2019-02-25 16:05:12,581 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:12,582 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:12,582 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:12,582 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_3 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:12,582 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000028_3 to list of failed maps
2019-02-25 16:05:12,583 INFO [IPC Server handler 24 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000030_2 is : 0.0
2019-02-25 16:05:12,588 FATAL [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000030_2 - exited : java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:12,588 INFO [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_2: Error: java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:12,588 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_2: Error: java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:12,589 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:12,589 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000043 taskAttempt attempt_1550090358635_0074_m_000030_2
2019-02-25 16:05:12,589 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000030_2
2019-02-25 16:05:12,589 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:12,592 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:12,592 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:12,593 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000030_2
2019-02-25 16:05:12,593 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:12,593 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:12,593 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:12,593 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_3 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:12,594 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000030_3 to list of failed maps
2019-02-25 16:05:12,610 INFO [IPC Server handler 0 on 42306] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Getting task report for MAP   job_1550090358635_0074. Report-size will be 32
2019-02-25 16:05:12,642 INFO [IPC Server handler 0 on 42306] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Getting task report for REDUCE   job_1550090358635_0074. Report-size will be 1
2019-02-25 16:05:12,647 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:30 ScheduledReds:0 AssignedMaps:26 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:42 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=0 finishedContainers=18 resourcelimit=<memory:482560, vCores:1> knownNMs=4
2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: Update the blacklist for application_1550090358635_0074: blacklistAdditions=0 blacklistRemovals=4
2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000043
2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000027
2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000023
2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000002
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_2: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000009
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000025_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000005
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000021_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000024
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000000_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000022
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000007_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000010
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000003_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000007
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000022_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000006
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000020_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000016
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000008_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000025
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000005_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000003
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000004_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000015
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000014_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000013
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000023_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000014
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000001_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000042
2019-02-25 16:05:12,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000013_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,650 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:482560, vCores:1>
2019-02-25 16:05:12,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000011_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,651 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:12,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000012_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,651 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:30 ScheduledReds:0 AssignedMaps:8 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:42 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:12,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_2: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:12,685 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:12,693 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:12,694 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000044 asked for a task
2019-02-25 16:05:12,694 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000044 given task: attempt_1550090358635_0074_m_000026_2
2019-02-25 16:05:12,702 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000045 asked for a task
2019-02-25 16:05:12,702 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000045 given task: attempt_1550090358635_0074_m_000031_2
2019-02-25 16:05:13,530 INFO [IPC Server handler 29 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000031_2 is : 0.0
2019-02-25 16:05:13,535 FATAL [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000031_2 - exited : java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:13,535 INFO [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000031_2: Error: java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:13,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000031_2: Error: java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:13,535 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:13,535 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000045 taskAttempt attempt_1550090358635_0074_m_000031_2
2019-02-25 16:05:13,536 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000031_2
2019-02-25 16:05:13,536 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:13,539 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:13,540 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:13,541 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000031_2
2019-02-25 16:05:13,541 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:13,541 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:13,541 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:13,541 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_3 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:13,542 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000031_3 to list of failed maps
2019-02-25 16:05:13,567 INFO [IPC Server handler 24 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000026_2 is : 0.0
2019-02-25 16:05:13,572 FATAL [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000026_2 - exited : java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:13,572 INFO [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_2: Error: java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:13,573 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_2: Error: java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:13,573 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:13,573 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000044 taskAttempt attempt_1550090358635_0074_m_000026_2
2019-02-25 16:05:13,573 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000026_2
2019-02-25 16:05:13,573 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:13,576 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:13,576 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:13,577 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000026_2
2019-02-25 16:05:13,578 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:13,578 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:13,578 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:13,578 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_3 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:13,578 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000026_3 to list of failed maps
2019-02-25 16:05:13,651 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:32 ScheduledReds:0 AssignedMaps:8 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:42 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:13,653 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=4 finishedContainers=8 resourcelimit=<memory:502656, vCores:1> knownNMs=4
2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000045
2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000026
2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000004
2019-02-25 16:05:13,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000031_2: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000012
2019-02-25 16:05:13,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000024_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000008
2019-02-25 16:05:13,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000002_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000019
2019-02-25 16:05:13,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000010_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000020
2019-02-25 16:05:13,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000006_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000044
2019-02-25 16:05:13,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000017_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 4
2019-02-25 16:05:13,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000018_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:13,654 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_2: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000046, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000046 to attempt_1550090358635_0074_m_000016_1
2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000047, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:13,654 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000047 to attempt_1550090358635_0074_m_000009_1
2019-02-25 16:05:13,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000048, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:13,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:13,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000048 to attempt_1550090358635_0074_m_000015_1
2019-02-25 16:05:13,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000049, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:13,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:13,655 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:13,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000049 to attempt_1550090358635_0074_m_000019_1
2019-02-25 16:05:13,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:502656, vCores:1>
2019-02-25 16:05:13,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:13,655 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:28 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:46 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:13,655 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:13,655 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:13,656 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:13,656 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:13,656 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:13,656 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:13,656 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:13,657 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000046 taskAttempt attempt_1550090358635_0074_m_000016_1
2019-02-25 16:05:13,657 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000047 taskAttempt attempt_1550090358635_0074_m_000009_1
2019-02-25 16:05:13,657 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000049 taskAttempt attempt_1550090358635_0074_m_000019_1
2019-02-25 16:05:13,657 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000048 taskAttempt attempt_1550090358635_0074_m_000015_1
2019-02-25 16:05:13,657 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000019_1
2019-02-25 16:05:13,657 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000015_1
2019-02-25 16:05:13,657 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000009_1
2019-02-25 16:05:13,657 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:13,657 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000016_1
2019-02-25 16:05:13,658 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:13,658 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:13,659 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:13,662 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000019_1 : 13562
2019-02-25 16:05:13,662 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000019_1] using containerId: [container_1550090358635_0074_01_000049 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:13,662 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:13,662 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000016_1 : 13562
2019-02-25 16:05:13,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000016_1] using containerId: [container_1550090358635_0074_01_000046 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:13,663 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000009_1 : 13562
2019-02-25 16:05:13,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:13,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000009_1] using containerId: [container_1550090358635_0074_01_000047 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:13,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:13,663 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000015_1 : 13562
2019-02-25 16:05:13,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000015_1] using containerId: [container_1550090358635_0074_01_000048 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:13,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=4 finishedContainers=0 resourcelimit=<memory:482560, vCores:1> knownNMs=4
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 4
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000050, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000050 to attempt_1550090358635_0074_m_000027_2
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000051, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000051 to attempt_1550090358635_0074_m_000021_1
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000052, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000052 to attempt_1550090358635_0074_m_000025_1
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000053, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000053 to attempt_1550090358635_0074_m_000029_2
2019-02-25 16:05:14,657 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:482560, vCores:1>
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:14,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:24 ScheduledReds:0 AssignedMaps:8 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:50 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:14,657 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:14,658 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:14,658 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:14,658 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:14,658 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:14,658 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:14,658 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:14,658 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000050 taskAttempt attempt_1550090358635_0074_m_000027_2
2019-02-25 16:05:14,658 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000051 taskAttempt attempt_1550090358635_0074_m_000021_1
2019-02-25 16:05:14,658 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000053 taskAttempt attempt_1550090358635_0074_m_000029_2
2019-02-25 16:05:14,658 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000052 taskAttempt attempt_1550090358635_0074_m_000025_1
2019-02-25 16:05:14,658 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000027_2
2019-02-25 16:05:14,658 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000025_1
2019-02-25 16:05:14,658 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000029_2
2019-02-25 16:05:14,658 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000021_1
2019-02-25 16:05:14,659 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:14,659 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:14,660 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:14,661 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:14,663 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000021_1 : 13562
2019-02-25 16:05:14,663 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000027_2 : 13562
2019-02-25 16:05:14,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000021_1] using containerId: [container_1550090358635_0074_01_000051 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:14,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:14,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000027_2] using containerId: [container_1550090358635_0074_01_000050 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:14,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:14,664 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000025_1 : 13562
2019-02-25 16:05:14,664 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000029_2 : 13562
2019-02-25 16:05:14,664 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000025_1] using containerId: [container_1550090358635_0074_01_000052 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:14,664 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:14,664 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000029_2] using containerId: [container_1550090358635_0074_01_000053 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:14,664 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:14,668 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:14,677 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000049 asked for a task
2019-02-25 16:05:14,677 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000049 given task: attempt_1550090358635_0074_m_000019_1
2019-02-25 16:05:14,686 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:14,695 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000048 asked for a task
2019-02-25 16:05:14,695 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000048 given task: attempt_1550090358635_0074_m_000015_1
2019-02-25 16:05:14,696 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:14,704 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000047 asked for a task
2019-02-25 16:05:14,704 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000047 given task: attempt_1550090358635_0074_m_000009_1
2019-02-25 16:05:14,706 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:14,715 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000046 asked for a task
2019-02-25 16:05:14,715 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000046 given task: attempt_1550090358635_0074_m_000016_1
2019-02-25 16:05:15,528 INFO [IPC Server handler 29 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000019_1 is : 0.0
2019-02-25 16:05:15,532 FATAL [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000019_1 - exited : java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,532 INFO [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000019_1: Error: java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,533 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000019_1: Error: java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,533 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:15,533 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000049 taskAttempt attempt_1550090358635_0074_m_000019_1
2019-02-25 16:05:15,533 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000019_1
2019-02-25 16:05:15,533 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:15,536 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:15,536 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:15,537 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000019_1
2019-02-25 16:05:15,537 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:15,538 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,538 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,538 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:15,538 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000019_2 to list of failed maps
2019-02-25 16:05:15,565 INFO [IPC Server handler 24 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000015_1 is : 0.0
2019-02-25 16:05:15,570 FATAL [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000015_1 - exited : java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,570 INFO [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000015_1: Error: java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,570 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000015_1: Error: java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,570 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:15,570 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000048 taskAttempt attempt_1550090358635_0074_m_000015_1
2019-02-25 16:05:15,570 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000015_1
2019-02-25 16:05:15,570 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:15,573 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:15,573 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:15,574 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000015_1
2019-02-25 16:05:15,574 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:15,575 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,575 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,575 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:15,575 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000015_2 to list of failed maps
2019-02-25 16:05:15,586 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000009_1 is : 0.0
2019-02-25 16:05:15,591 FATAL [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000009_1 - exited : java.io.IOException: map failure for key 'GCF_000691865.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,591 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000009_1: Error: java.io.IOException: map failure for key 'GCF_000691865.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,591 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000009_1: Error: java.io.IOException: map failure for key 'GCF_000691865.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,591 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:15,591 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000047 taskAttempt attempt_1550090358635_0074_m_000009_1
2019-02-25 16:05:15,592 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000009_1
2019-02-25 16:05:15,592 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:15,594 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:15,594 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:15,595 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000009_1
2019-02-25 16:05:15,595 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:15,595 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,595 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,595 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:15,595 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000009_2 to list of failed maps
2019-02-25 16:05:15,604 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000016_1 is : 0.0
2019-02-25 16:05:15,609 FATAL [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000016_1 - exited : java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,609 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000016_1: Error: java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000016_1: Error: java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:15,610 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000046 taskAttempt attempt_1550090358635_0074_m_000016_1
2019-02-25 16:05:15,610 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000016_1
2019-02-25 16:05:15,610 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:15,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:15,612 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:15,613 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000016_1
2019-02-25 16:05:15,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:15,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:15,614 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000016_2 to list of failed maps
2019-02-25 16:05:15,657 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:28 ScheduledReds:0 AssignedMaps:8 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:50 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=7 finishedContainers=4 resourcelimit=<memory:467488, vCores:1> knownNMs=4
2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000048
2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000046
2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000049
2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000047
2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 7
2019-02-25 16:05:15,659 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000015_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000054, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:15,659 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000016_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:15,659 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000019_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000054 to attempt_1550090358635_0074_m_000007_1
2019-02-25 16:05:15,659 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000009_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000055, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000055 to attempt_1550090358635_0074_m_000003_1
2019-02-25 16:05:15,659 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000056, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000056 to attempt_1550090358635_0074_m_000000_1
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000057, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000057 to attempt_1550090358635_0074_m_000004_1
2019-02-25 16:05:15,660 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000058, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000058 to attempt_1550090358635_0074_m_000008_1
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000059, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000059 to attempt_1550090358635_0074_m_000022_1
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000060, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000060 to attempt_1550090358635_0074_m_000005_1
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:467488, vCores:1>
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:15,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:21 ScheduledReds:0 AssignedMaps:11 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:57 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:15,660 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:15,660 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,660 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:15,660 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,660 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:15,660 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,661 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:15,661 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,661 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:15,661 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,661 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:15,661 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:15,661 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:15,661 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000054 taskAttempt attempt_1550090358635_0074_m_000007_1
2019-02-25 16:05:15,661 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000055 taskAttempt attempt_1550090358635_0074_m_000003_1
2019-02-25 16:05:15,661 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000007_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000003_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000057 taskAttempt attempt_1550090358635_0074_m_000004_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000056 taskAttempt attempt_1550090358635_0074_m_000000_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000058 taskAttempt attempt_1550090358635_0074_m_000008_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000059 taskAttempt attempt_1550090358635_0074_m_000022_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000004_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:15,662 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000022_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000060 taskAttempt attempt_1550090358635_0074_m_000005_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000008_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000000_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000005_1
2019-02-25 16:05:15,662 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:15,663 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:15,663 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:15,664 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:15,664 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:15,665 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:15,666 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000005_1 : 13562
2019-02-25 16:05:15,666 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000007_1 : 13562
2019-02-25 16:05:15,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000005_1] using containerId: [container_1550090358635_0074_01_000060 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:15,666 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000008_1 : 13562
2019-02-25 16:05:15,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:15,666 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000000_1 : 13562
2019-02-25 16:05:15,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000007_1] using containerId: [container_1550090358635_0074_01_000054 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:15,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:15,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000008_1] using containerId: [container_1550090358635_0074_01_000058 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:15,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:15,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000000_1] using containerId: [container_1550090358635_0074_01_000056 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:15,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:15,667 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000022_1 : 13562
2019-02-25 16:05:15,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000022_1] using containerId: [container_1550090358635_0074_01_000059 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:15,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:15,668 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000004_1 : 13562
2019-02-25 16:05:15,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000004_1] using containerId: [container_1550090358635_0074_01_000057 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:15,668 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000003_1 : 13562
2019-02-25 16:05:15,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:15,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000003_1] using containerId: [container_1550090358635_0074_01_000055 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:15,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:15,695 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:15,703 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000053 asked for a task
2019-02-25 16:05:15,703 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000053 given task: attempt_1550090358635_0074_m_000029_2
2019-02-25 16:05:15,709 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:15,710 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:15,720 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000051 asked for a task
2019-02-25 16:05:15,720 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000051 given task: attempt_1550090358635_0074_m_000021_1
2019-02-25 16:05:15,720 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000052 asked for a task
2019-02-25 16:05:15,720 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000052 given task: attempt_1550090358635_0074_m_000025_1
2019-02-25 16:05:15,740 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:15,750 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000050 asked for a task
2019-02-25 16:05:15,750 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000050 given task: attempt_1550090358635_0074_m_000027_2
2019-02-25 16:05:16,576 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000029_2 is : 0.0
2019-02-25 16:05:16,581 FATAL [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000029_2 - exited : java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,581 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000029_2: Error: java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,581 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000029_2: Error: java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,581 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:16,582 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000053 taskAttempt attempt_1550090358635_0074_m_000029_2
2019-02-25 16:05:16,582 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000029_2
2019-02-25 16:05:16,582 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:16,585 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:16,585 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:16,586 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000029_2
2019-02-25 16:05:16,586 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:16,586 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,586 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,586 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_3 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:16,587 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000029_3 to list of failed maps
2019-02-25 16:05:16,612 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000021_1 is : 0.0
2019-02-25 16:05:16,617 FATAL [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000021_1 - exited : java.io.IOException: map failure for key 'GCF_002155895.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,617 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000021_1: Error: java.io.IOException: map failure for key 'GCF_002155895.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000021_1: Error: java.io.IOException: map failure for key 'GCF_002155895.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,618 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:16,618 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000051 taskAttempt attempt_1550090358635_0074_m_000021_1
2019-02-25 16:05:16,618 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000021_1
2019-02-25 16:05:16,618 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:16,620 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000025_1 is : 0.0
2019-02-25 16:05:16,621 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:16,622 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:16,622 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000021_1
2019-02-25 16:05:16,623 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:16,623 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,623 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,623 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:16,623 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000021_2 to list of failed maps
2019-02-25 16:05:16,625 FATAL [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000025_1 - exited : java.io.IOException: map failure for key 'GCF_003062915.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,625 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000025_1: Error: java.io.IOException: map failure for key 'GCF_003062915.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000025_1: Error: java.io.IOException: map failure for key 'GCF_003062915.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,626 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:16,626 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000052 taskAttempt attempt_1550090358635_0074_m_000025_1
2019-02-25 16:05:16,626 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000025_1
2019-02-25 16:05:16,626 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:16,629 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:16,629 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:16,630 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000025_1
2019-02-25 16:05:16,630 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:16,630 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,630 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,630 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:16,630 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000025_2 to list of failed maps
2019-02-25 16:05:16,644 INFO [IPC Server handler 9 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000027_2 is : 0.0
2019-02-25 16:05:16,649 FATAL [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000027_2 - exited : java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,649 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000027_2: Error: java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,649 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000027_2: Error: java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,649 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:16,649 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000050 taskAttempt attempt_1550090358635_0074_m_000027_2
2019-02-25 16:05:16,650 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000027_2
2019-02-25 16:05:16,650 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:16,652 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:16,652 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:16,653 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000027_2
2019-02-25 16:05:16,653 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:16,653 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,653 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,653 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_3 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:16,653 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000027_3 to list of failed maps
2019-02-25 16:05:16,660 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:25 ScheduledReds:0 AssignedMaps:11 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:57 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=7 finishedContainers=3 resourcelimit=<memory:447392, vCores:1> knownNMs=4
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000052
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000053
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000051
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 7
2019-02-25 16:05:16,662 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000025_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:16,662 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000029_2: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:16,662 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000021_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000061, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000061 to attempt_1550090358635_0074_m_000014_1
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000062, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000062 to attempt_1550090358635_0074_m_000020_1
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000063, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:16,662 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000063 to attempt_1550090358635_0074_m_000001_1
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000064, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000064 to attempt_1550090358635_0074_m_000013_1
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000065, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000065 to attempt_1550090358635_0074_m_000011_1
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000066, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000066 to attempt_1550090358635_0074_m_000023_1
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000067, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:16,662 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000067 to attempt_1550090358635_0074_m_000012_1
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:447392, vCores:1>
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:16,662 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:18 ScheduledReds:0 AssignedMaps:15 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:64 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:16,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:16,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:16,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:16,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:16,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,664 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:16,664 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:16,664 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000061 taskAttempt attempt_1550090358635_0074_m_000014_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000014_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:16,664 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:16,664 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000062 taskAttempt attempt_1550090358635_0074_m_000020_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000063 taskAttempt attempt_1550090358635_0074_m_000001_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000064 taskAttempt attempt_1550090358635_0074_m_000013_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000013_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000020_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000066 taskAttempt attempt_1550090358635_0074_m_000023_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000067 taskAttempt attempt_1550090358635_0074_m_000012_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000065 taskAttempt attempt_1550090358635_0074_m_000011_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000001_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000011_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:16,664 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000012_1
2019-02-25 16:05:16,664 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000023_1
2019-02-25 16:05:16,665 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:16,665 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:16,666 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:16,666 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:16,667 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:16,667 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000014_1 : 13562
2019-02-25 16:05:16,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000014_1] using containerId: [container_1550090358635_0074_01_000061 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:16,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:16,668 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000020_1 : 13562
2019-02-25 16:05:16,668 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000023_1 : 13562
2019-02-25 16:05:16,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000020_1] using containerId: [container_1550090358635_0074_01_000062 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:16,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:16,668 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000012_1 : 13562
2019-02-25 16:05:16,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000023_1] using containerId: [container_1550090358635_0074_01_000066 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:16,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:16,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000012_1] using containerId: [container_1550090358635_0074_01_000067 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:16,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:16,668 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000011_1 : 13562
2019-02-25 16:05:16,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000011_1] using containerId: [container_1550090358635_0074_01_000065 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:16,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:16,670 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000001_1 : 13562
2019-02-25 16:05:16,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000001_1] using containerId: [container_1550090358635_0074_01_000063 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:16,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:16,670 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000013_1 : 13562
2019-02-25 16:05:16,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000013_1] using containerId: [container_1550090358635_0074_01_000064 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:16,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:16,692 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:16,702 INFO [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000056 asked for a task
2019-02-25 16:05:16,702 INFO [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000056 given task: attempt_1550090358635_0074_m_000000_1
2019-02-25 16:05:16,744 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:16,745 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:16,752 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:16,754 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000058 asked for a task
2019-02-25 16:05:16,754 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000058 given task: attempt_1550090358635_0074_m_000008_1
2019-02-25 16:05:16,754 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000055 asked for a task
2019-02-25 16:05:16,754 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000055 given task: attempt_1550090358635_0074_m_000003_1
2019-02-25 16:05:16,756 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:16,762 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:16,762 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000057 asked for a task
2019-02-25 16:05:16,762 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000057 given task: attempt_1550090358635_0074_m_000004_1
2019-02-25 16:05:16,765 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000060 asked for a task
2019-02-25 16:05:16,765 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000060 given task: attempt_1550090358635_0074_m_000005_1
2019-02-25 16:05:16,771 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:16,771 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000054 asked for a task
2019-02-25 16:05:16,771 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000054 given task: attempt_1550090358635_0074_m_000007_1
2019-02-25 16:05:16,780 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000059 asked for a task
2019-02-25 16:05:16,780 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000059 given task: attempt_1550090358635_0074_m_000022_1
2019-02-25 16:05:17,600 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000000_1 is : 0.0
2019-02-25 16:05:17,605 FATAL [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000000_1 - exited : java.io.IOException: map failure for key 'GCF_000001215.4'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,605 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000000_1: Error: java.io.IOException: map failure for key 'GCF_000001215.4'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000000_1: Error: java.io.IOException: map failure for key 'GCF_000001215.4'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,606 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:17,606 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000056 taskAttempt attempt_1550090358635_0074_m_000000_1
2019-02-25 16:05:17,606 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000000_1
2019-02-25 16:05:17,606 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:17,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:17,609 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:17,610 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000000_1
2019-02-25 16:05:17,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:17,610 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,611 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:17,611 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000000_2 to list of failed maps
2019-02-25 16:05:17,620 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000003_1 is : 0.0
2019-02-25 16:05:17,625 FATAL [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000003_1 - exited : java.io.IOException: map failure for key 'GCF_000237025.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,625 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000003_1: Error: java.io.IOException: map failure for key 'GCF_000237025.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000003_1: Error: java.io.IOException: map failure for key 'GCF_000237025.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:17,625 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000055 taskAttempt attempt_1550090358635_0074_m_000003_1
2019-02-25 16:05:17,625 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000003_1
2019-02-25 16:05:17,625 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:17,628 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:17,628 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:17,629 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000003_1
2019-02-25 16:05:17,629 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:17,629 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,629 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,629 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:17,629 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000003_2 to list of failed maps
2019-02-25 16:05:17,658 INFO [IPC Server handler 11 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000022_1 is : 0.0
2019-02-25 16:05:17,662 FATAL [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000022_1 - exited : java.io.IOException: map failure for key 'GCF_002289615.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,662 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000022_1: Error: java.io.IOException: map failure for key 'GCF_002289615.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,662 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000022_1: Error: java.io.IOException: map failure for key 'GCF_002289615.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:17,663 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:20 ScheduledReds:0 AssignedMaps:15 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:64 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:17,663 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000059 taskAttempt attempt_1550090358635_0074_m_000022_1
2019-02-25 16:05:17,663 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000022_1
2019-02-25 16:05:17,663 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:17,665 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=5 finishedContainers=3 resourcelimit=<memory:437344, vCores:1> knownNMs=4
2019-02-25 16:05:17,665 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000050
2019-02-25 16:05:17,665 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000056
2019-02-25 16:05:17,665 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000027_2: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:17,665 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000055
2019-02-25 16:05:17,665 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000000_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:17,665 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000003_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:17,665 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 5
2019-02-25 16:05:17,665 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000068, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:17,665 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000068 to attempt_1550090358635_0074_m_000002_1
2019-02-25 16:05:17,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000069, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000069 to attempt_1550090358635_0074_m_000010_1
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000070, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000070 to attempt_1550090358635_0074_m_000024_1
2019-02-25 16:05:17,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000071, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000071 to attempt_1550090358635_0074_m_000018_1
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000072, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000072 to attempt_1550090358635_0074_m_000017_1
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:437344, vCores:1>
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:17,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:15 ScheduledReds:0 AssignedMaps:17 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:69 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:17,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:17,666 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:17,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:17,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:17,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:17,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,667 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000022_1
2019-02-25 16:05:17,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:17,667 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000068 taskAttempt attempt_1550090358635_0074_m_000002_1
2019-02-25 16:05:17,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:17,667 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000069 taskAttempt attempt_1550090358635_0074_m_000010_1
2019-02-25 16:05:17,667 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000070 taskAttempt attempt_1550090358635_0074_m_000024_1
2019-02-25 16:05:17,667 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000071 taskAttempt attempt_1550090358635_0074_m_000018_1
2019-02-25 16:05:17,667 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000002_1
2019-02-25 16:05:17,667 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000072 taskAttempt attempt_1550090358635_0074_m_000017_1
2019-02-25 16:05:17,667 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:17,667 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000017_1
2019-02-25 16:05:17,667 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000018_1
2019-02-25 16:05:17,667 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000024_1
2019-02-25 16:05:17,667 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000010_1
2019-02-25 16:05:17,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:17,667 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000022_2 to list of failed maps
2019-02-25 16:05:17,668 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:17,668 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:17,669 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:17,669 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:17,671 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000002_1 : 13562
2019-02-25 16:05:17,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000002_1] using containerId: [container_1550090358635_0074_01_000068 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:17,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:17,671 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000010_1 : 13562
2019-02-25 16:05:17,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000010_1] using containerId: [container_1550090358635_0074_01_000069 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:17,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:17,671 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000024_1 : 13562
2019-02-25 16:05:17,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000024_1] using containerId: [container_1550090358635_0074_01_000070 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:17,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:17,672 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000018_1 : 13562
2019-02-25 16:05:17,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000018_1] using containerId: [container_1550090358635_0074_01_000071 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:17,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:17,674 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000017_1 : 13562
2019-02-25 16:05:17,674 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000017_1] using containerId: [container_1550090358635_0074_01_000072 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:17,674 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:17,696 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000004_1 is : 0.0
2019-02-25 16:05:17,701 FATAL [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000004_1 - exited : java.io.IOException: map failure for key 'GCF_000323305.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,701 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000004_1: Error: java.io.IOException: map failure for key 'GCF_000323305.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,702 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000004_1: Error: java.io.IOException: map failure for key 'GCF_000323305.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,702 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000005_1 is : 0.0
2019-02-25 16:05:17,702 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:17,702 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000057 taskAttempt attempt_1550090358635_0074_m_000004_1
2019-02-25 16:05:17,702 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000004_1
2019-02-25 16:05:17,702 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:17,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:17,705 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:17,706 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000004_1
2019-02-25 16:05:17,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:17,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:17,706 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000004_2 to list of failed maps
2019-02-25 16:05:17,706 FATAL [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000005_1 - exited : java.io.IOException: map failure for key 'GCF_000390385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,706 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000005_1: Error: java.io.IOException: map failure for key 'GCF_000390385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000005_1: Error: java.io.IOException: map failure for key 'GCF_000390385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,706 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:17,707 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000060 taskAttempt attempt_1550090358635_0074_m_000005_1
2019-02-25 16:05:17,707 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000005_1
2019-02-25 16:05:17,707 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:17,709 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:17,709 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:17,710 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000005_1
2019-02-25 16:05:17,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:17,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:17,710 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000005_2 to list of failed maps
2019-02-25 16:05:17,724 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:17,731 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:17,735 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000064 asked for a task
2019-02-25 16:05:17,735 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000064 given task: attempt_1550090358635_0074_m_000013_1
2019-02-25 16:05:17,739 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000061 asked for a task
2019-02-25 16:05:17,740 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000061 given task: attempt_1550090358635_0074_m_000014_1
2019-02-25 16:05:17,753 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000007_1 is : 0.0
2019-02-25 16:05:17,756 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:17,758 FATAL [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000007_1 - exited : java.io.IOException: map failure for key 'GCF_000517545.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,758 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000007_1: Error: java.io.IOException: map failure for key 'GCF_000517545.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,758 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000007_1: Error: java.io.IOException: map failure for key 'GCF_000517545.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,758 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:17,758 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000054 taskAttempt attempt_1550090358635_0074_m_000007_1
2019-02-25 16:05:17,759 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000007_1
2019-02-25 16:05:17,759 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:17,761 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:17,761 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:17,762 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000007_1
2019-02-25 16:05:17,762 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:17,763 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,763 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,763 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:17,763 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000007_2 to list of failed maps
2019-02-25 16:05:17,764 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:17,765 INFO [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000008_1 is : 0.0
2019-02-25 16:05:17,765 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000065 asked for a task
2019-02-25 16:05:17,765 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000065 given task: attempt_1550090358635_0074_m_000011_1
2019-02-25 16:05:17,766 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:17,769 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:17,770 FATAL [IPC Server handler 23 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000008_1 - exited : java.io.IOException: map failure for key 'GCF_000622325.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,770 INFO [IPC Server handler 23 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000008_1: Error: java.io.IOException: map failure for key 'GCF_000622325.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,770 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000008_1: Error: java.io.IOException: map failure for key 'GCF_000622325.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,770 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:17,770 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000058 taskAttempt attempt_1550090358635_0074_m_000008_1
2019-02-25 16:05:17,770 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000008_1
2019-02-25 16:05:17,770 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:17,773 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:17,773 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:17,773 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:17,773 INFO [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000067 asked for a task
2019-02-25 16:05:17,773 INFO [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000067 given task: attempt_1550090358635_0074_m_000012_1
2019-02-25 16:05:17,774 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000008_1
2019-02-25 16:05:17,774 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:17,774 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,774 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:17,774 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:17,774 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000008_2 to list of failed maps
2019-02-25 16:05:17,776 INFO [IPC Server handler 22 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000062 asked for a task
2019-02-25 16:05:17,776 INFO [IPC Server handler 22 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000062 given task: attempt_1550090358635_0074_m_000020_1
2019-02-25 16:05:17,779 INFO [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000066 asked for a task
2019-02-25 16:05:17,779 INFO [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000066 given task: attempt_1550090358635_0074_m_000023_1
2019-02-25 16:05:17,782 INFO [IPC Server handler 29 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000063 asked for a task
2019-02-25 16:05:17,782 INFO [IPC Server handler 29 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000063 given task: attempt_1550090358635_0074_m_000001_1
2019-02-25 16:05:18,604 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000014_1 is : 0.0
2019-02-25 16:05:18,609 FATAL [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000014_1 - exited : java.io.IOException: map failure for key 'GCF_001218505.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,609 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000014_1: Error: java.io.IOException: map failure for key 'GCF_001218505.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000014_1: Error: java.io.IOException: map failure for key 'GCF_001218505.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:18,610 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000061 taskAttempt attempt_1550090358635_0074_m_000014_1
2019-02-25 16:05:18,610 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000014_1
2019-02-25 16:05:18,610 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:18,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:18,613 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:18,614 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000014_1
2019-02-25 16:05:18,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:18,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:18,614 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000014_2 to list of failed maps
2019-02-25 16:05:18,616 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000013_1 is : 0.0
2019-02-25 16:05:18,621 FATAL [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000013_1 - exited : java.io.IOException: map failure for key 'GCF_001083795.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,621 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000013_1: Error: java.io.IOException: map failure for key 'GCF_001083795.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,621 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000013_1: Error: java.io.IOException: map failure for key 'GCF_001083795.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,621 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:18,622 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000064 taskAttempt attempt_1550090358635_0074_m_000013_1
2019-02-25 16:05:18,622 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000013_1
2019-02-25 16:05:18,622 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:18,624 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:18,624 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:18,625 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000013_1
2019-02-25 16:05:18,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:18,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,625 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:18,625 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000013_2 to list of failed maps
2019-02-25 16:05:18,642 INFO [IPC Server handler 9 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000011_1 is : 0.0
2019-02-25 16:05:18,646 FATAL [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000011_1 - exited : java.io.IOException: map failure for key 'GCF_000767605.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,646 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000011_1: Error: java.io.IOException: map failure for key 'GCF_000767605.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,647 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000011_1: Error: java.io.IOException: map failure for key 'GCF_000767605.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,647 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:18,647 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000065 taskAttempt attempt_1550090358635_0074_m_000011_1
2019-02-25 16:05:18,647 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000011_1
2019-02-25 16:05:18,647 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:18,650 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:18,650 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:18,651 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000011_1
2019-02-25 16:05:18,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:18,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,651 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:18,651 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000011_2 to list of failed maps
2019-02-25 16:05:18,666 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:23 ScheduledReds:0 AssignedMaps:17 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:69 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=9 finishedContainers=8 resourcelimit=<memory:432320, vCores:1> knownNMs=4
2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000057
2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000058
2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000059
2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000054
2019-02-25 16:05:18,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000004_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000064
2019-02-25 16:05:18,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000008_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:18,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000022_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:18,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000007_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000061
2019-02-25 16:05:18,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000013_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:18,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000014_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000060
2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000065
2019-02-25 16:05:18,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000005_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:18,668 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 9
2019-02-25 16:05:18,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000011_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000073, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000073 to attempt_1550090358635_0074_m_000006_1
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000074, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000074 to attempt_1550090358635_0074_m_000028_3
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000075, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000075 to attempt_1550090358635_0074_m_000030_3
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000076, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:18,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000076 to attempt_1550090358635_0074_m_000031_3
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000077, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000077 to attempt_1550090358635_0074_m_000026_3
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000078, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000078 to attempt_1550090358635_0074_m_000019_2
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000079, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000079 to attempt_1550090358635_0074_m_000015_2
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000080, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000080 to attempt_1550090358635_0074_m_000009_2
2019-02-25 16:05:18,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000081, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000081 to attempt_1550090358635_0074_m_000016_2
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:432320, vCores:1>
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:18,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:14 ScheduledReds:0 AssignedMaps:18 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:78 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:18,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_3 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:18,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_3 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:18,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_3 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:18,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_3 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:18,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:18,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:18,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:18,671 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000073 taskAttempt attempt_1550090358635_0074_m_000006_1
2019-02-25 16:05:18,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,671 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000006_1
2019-02-25 16:05:18,671 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:18,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:18,671 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000074 taskAttempt attempt_1550090358635_0074_m_000028_3
2019-02-25 16:05:18,671 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000028_3
2019-02-25 16:05:18,671 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000075 taskAttempt attempt_1550090358635_0074_m_000030_3
2019-02-25 16:05:18,671 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000030_3
2019-02-25 16:05:18,671 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000076 taskAttempt attempt_1550090358635_0074_m_000031_3
2019-02-25 16:05:18,671 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000077 taskAttempt attempt_1550090358635_0074_m_000026_3
2019-02-25 16:05:18,671 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000078 taskAttempt attempt_1550090358635_0074_m_000019_2
2019-02-25 16:05:18,671 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000031_3
2019-02-25 16:05:18,671 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000019_2
2019-02-25 16:05:18,671 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000079 taskAttempt attempt_1550090358635_0074_m_000015_2
2019-02-25 16:05:18,671 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000026_3
2019-02-25 16:05:18,671 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000081 taskAttempt attempt_1550090358635_0074_m_000016_2
2019-02-25 16:05:18,671 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000015_2
2019-02-25 16:05:18,671 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000080 taskAttempt attempt_1550090358635_0074_m_000009_2
2019-02-25 16:05:18,671 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:18,671 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000009_2
2019-02-25 16:05:18,671 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000016_2
2019-02-25 16:05:18,672 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:18,673 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000012_1 is : 0.0
2019-02-25 16:05:18,673 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:18,673 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:18,674 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:18,674 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:18,674 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:18,674 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000016_2 : 13562
2019-02-25 16:05:18,674 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:18,675 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000006_1 : 13562
2019-02-25 16:05:18,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000016_2] using containerId: [container_1550090358635_0074_01_000081 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:18,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:18,675 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000026_3 : 13562
2019-02-25 16:05:18,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000006_1] using containerId: [container_1550090358635_0074_01_000073 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:18,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_1 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:18,675 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000009_2 : 13562
2019-02-25 16:05:18,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000026_3] using containerId: [container_1550090358635_0074_01_000077 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:18,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_3 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:18,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000009_2] using containerId: [container_1550090358635_0074_01_000080 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:18,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:18,676 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000015_2 : 13562
2019-02-25 16:05:18,676 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000019_2 : 13562
2019-02-25 16:05:18,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000015_2] using containerId: [container_1550090358635_0074_01_000079 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:18,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:18,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000019_2] using containerId: [container_1550090358635_0074_01_000078 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:18,676 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000031_3 : 13562
2019-02-25 16:05:18,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:18,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000031_3] using containerId: [container_1550090358635_0074_01_000076 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:18,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_3 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:18,676 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000030_3 : 13562
2019-02-25 16:05:18,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000030_3] using containerId: [container_1550090358635_0074_01_000075 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:18,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_3 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:18,677 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000028_3 : 13562
2019-02-25 16:05:18,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000028_3] using containerId: [container_1550090358635_0074_01_000074 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:18,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_3 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:18,678 FATAL [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000012_1 - exited : java.io.IOException: map failure for key 'GCF_000935645.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,678 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000012_1: Error: java.io.IOException: map failure for key 'GCF_000935645.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,678 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000012_1: Error: java.io.IOException: map failure for key 'GCF_000935645.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,678 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:18,678 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000067 taskAttempt attempt_1550090358635_0074_m_000012_1
2019-02-25 16:05:18,678 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000012_1
2019-02-25 16:05:18,678 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:18,680 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:18,680 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:18,681 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000012_1
2019-02-25 16:05:18,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:18,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:18,682 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000012_2 to list of failed maps
2019-02-25 16:05:18,683 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000001_1 is : 0.0
2019-02-25 16:05:18,687 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000023_1 is : 0.0
2019-02-25 16:05:18,688 FATAL [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000001_1 - exited : java.io.IOException: map failure for key 'GCF_000146835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,688 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000001_1: Error: java.io.IOException: map failure for key 'GCF_000146835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,688 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000001_1: Error: java.io.IOException: map failure for key 'GCF_000146835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,688 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:18,688 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000063 taskAttempt attempt_1550090358635_0074_m_000001_1
2019-02-25 16:05:18,688 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000001_1
2019-02-25 16:05:18,688 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:18,691 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:18,691 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:18,691 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000001_1
2019-02-25 16:05:18,691 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:18,692 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,692 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,692 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:18,692 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000001_2 to list of failed maps
2019-02-25 16:05:18,692 FATAL [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000023_1 - exited : java.io.IOException: map failure for key 'GCF_002708555.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,692 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000023_1: Error: java.io.IOException: map failure for key 'GCF_002708555.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,692 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000023_1: Error: java.io.IOException: map failure for key 'GCF_002708555.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,692 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:18,692 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000066 taskAttempt attempt_1550090358635_0074_m_000023_1
2019-02-25 16:05:18,693 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000023_1
2019-02-25 16:05:18,693 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:18,695 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:18,695 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:18,695 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000023_1
2019-02-25 16:05:18,695 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:18,695 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,696 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,696 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:18,696 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000023_2 to list of failed maps
2019-02-25 16:05:18,731 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:18,738 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:18,741 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000071 asked for a task
2019-02-25 16:05:18,741 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000071 given task: attempt_1550090358635_0074_m_000018_1
2019-02-25 16:05:18,741 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:18,748 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000068 asked for a task
2019-02-25 16:05:18,748 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000068 given task: attempt_1550090358635_0074_m_000002_1
2019-02-25 16:05:18,748 INFO [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000020_1 is : 0.0
2019-02-25 16:05:18,751 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000072 asked for a task
2019-02-25 16:05:18,751 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000072 given task: attempt_1550090358635_0074_m_000017_1
2019-02-25 16:05:18,753 FATAL [IPC Server handler 23 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000020_1 - exited : java.io.IOException: map failure for key 'GCF_002007485.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,753 INFO [IPC Server handler 23 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000020_1: Error: java.io.IOException: map failure for key 'GCF_002007485.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,753 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000020_1: Error: java.io.IOException: map failure for key 'GCF_002007485.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,753 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:18,753 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000062 taskAttempt attempt_1550090358635_0074_m_000020_1
2019-02-25 16:05:18,753 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000020_1
2019-02-25 16:05:18,753 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:18,757 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:18,757 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:18,758 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000020_1
2019-02-25 16:05:18,758 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:18,758 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,758 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:18,758 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:18,758 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000020_2 to list of failed maps
2019-02-25 16:05:18,772 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:18,773 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:18,782 INFO [IPC Server handler 29 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000070 asked for a task
2019-02-25 16:05:18,782 INFO [IPC Server handler 29 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000070 given task: attempt_1550090358635_0074_m_000024_1
2019-02-25 16:05:18,782 INFO [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000069 asked for a task
2019-02-25 16:05:18,782 INFO [IPC Server handler 27 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000069 given task: attempt_1550090358635_0074_m_000010_1
2019-02-25 16:05:19,015 INFO [IPC Server handler 0 on 42306] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Getting task report for MAP   job_1550090358635_0074. Report-size will be 32
2019-02-25 16:05:19,035 INFO [IPC Server handler 0 on 42306] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Getting task report for REDUCE   job_1550090358635_0074. Report-size will be 1
2019-02-25 16:05:19,658 INFO [IPC Server handler 10 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000010_1 is : 0.0
2019-02-25 16:05:19,661 INFO [IPC Server handler 13 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000017_1 is : 0.0
2019-02-25 16:05:19,663 FATAL [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000010_1 - exited : java.io.IOException: map failure for key 'GCF_000708245.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,663 INFO [IPC Server handler 12 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000010_1: Error: java.io.IOException: map failure for key 'GCF_000708245.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,663 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000010_1: Error: java.io.IOException: map failure for key 'GCF_000708245.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,664 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:19,664 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000069 taskAttempt attempt_1550090358635_0074_m_000010_1
2019-02-25 16:05:19,664 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000010_1
2019-02-25 16:05:19,664 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:19,666 FATAL [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000017_1 - exited : java.io.IOException: map failure for key 'GCF_001574785.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,666 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000017_1: Error: java.io.IOException: map failure for key 'GCF_001574785.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000017_1: Error: java.io.IOException: map failure for key 'GCF_001574785.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,666 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:19,666 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000072 taskAttempt attempt_1550090358635_0074_m_000017_1
2019-02-25 16:05:19,666 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000017_1
2019-02-25 16:05:19,666 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:19,667 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:19,667 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:19,668 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000010_1
2019-02-25 16:05:19,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:19,668 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:19,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,669 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:19,669 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:19,669 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000010_2 to list of failed maps
2019-02-25 16:05:19,669 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:19 ScheduledReds:0 AssignedMaps:18 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:78 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:19,669 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000017_1
2019-02-25 16:05:19,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:19,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=5 finishedContainers=4 resourcelimit=<memory:427296, vCores:1> knownNMs=4
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000066
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000062
2019-02-25 16:05:19,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000023_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000063
2019-02-25 16:05:19,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000020_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000067
2019-02-25 16:05:19,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000001_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 5
2019-02-25 16:05:19,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000012_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000082, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000082 to attempt_1550090358635_0074_m_000029_3
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000083, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000083 to attempt_1550090358635_0074_m_000021_2
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000084, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:19,671 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000084 to attempt_1550090358635_0074_m_000025_2
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000085, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000085 to attempt_1550090358635_0074_m_000027_3
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000086, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:19,671 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000086 to attempt_1550090358635_0074_m_000000_2
2019-02-25 16:05:19,672 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:427296, vCores:1>
2019-02-25 16:05:19,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_3 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:19,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:19,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:19,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,672 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:19,672 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:14 ScheduledReds:0 AssignedMaps:19 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:83 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:19,672 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000017_2 to list of failed maps
2019-02-25 16:05:19,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_3 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:19,672 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,673 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:19,673 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000082 taskAttempt attempt_1550090358635_0074_m_000029_3
2019-02-25 16:05:19,673 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000083 taskAttempt attempt_1550090358635_0074_m_000021_2
2019-02-25 16:05:19,673 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000029_3
2019-02-25 16:05:19,673 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000084 taskAttempt attempt_1550090358635_0074_m_000025_2
2019-02-25 16:05:19,673 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:19,673 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000025_2
2019-02-25 16:05:19,673 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000086 taskAttempt attempt_1550090358635_0074_m_000000_2
2019-02-25 16:05:19,673 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000021_2
2019-02-25 16:05:19,673 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000000_2
2019-02-25 16:05:19,673 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000085 taskAttempt attempt_1550090358635_0074_m_000027_3
2019-02-25 16:05:19,673 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000027_3
2019-02-25 16:05:19,673 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:19,674 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:19,674 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:19,674 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:19,676 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000029_3 : 13562
2019-02-25 16:05:19,676 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000027_3 : 13562
2019-02-25 16:05:19,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000029_3] using containerId: [container_1550090358635_0074_01_000082 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:19,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_3 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:19,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000027_3] using containerId: [container_1550090358635_0074_01_000085 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:19,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_3 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:19,677 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000000_2 : 13562
2019-02-25 16:05:19,677 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000021_2 : 13562
2019-02-25 16:05:19,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000000_2] using containerId: [container_1550090358635_0074_01_000086 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:19,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:19,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000021_2] using containerId: [container_1550090358635_0074_01_000083 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:19,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:19,677 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000025_2 : 13562
2019-02-25 16:05:19,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000025_2] using containerId: [container_1550090358635_0074_01_000084 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:19,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:19,700 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000024_1 is : 0.0
2019-02-25 16:05:19,705 FATAL [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000024_1 - exited : java.io.IOException: map failure for key 'GCF_002901215.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,705 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000024_1: Error: java.io.IOException: map failure for key 'GCF_002901215.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000024_1: Error: java.io.IOException: map failure for key 'GCF_002901215.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:19,706 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000070 taskAttempt attempt_1550090358635_0074_m_000024_1
2019-02-25 16:05:19,706 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000024_1
2019-02-25 16:05:19,706 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:19,708 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:19,708 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:19,709 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000024_1
2019-02-25 16:05:19,709 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:19,709 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:19,710 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000024_2 to list of failed maps
2019-02-25 16:05:19,756 INFO [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000018_1 is : 0.0
2019-02-25 16:05:19,761 FATAL [IPC Server handler 22 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000018_1 - exited : java.io.IOException: map failure for key 'GCF_001682715.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,761 INFO [IPC Server handler 22 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000018_1: Error: java.io.IOException: map failure for key 'GCF_001682715.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,761 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000018_1: Error: java.io.IOException: map failure for key 'GCF_001682715.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,761 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:19,761 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000071 taskAttempt attempt_1550090358635_0074_m_000018_1
2019-02-25 16:05:19,761 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000018_1
2019-02-25 16:05:19,761 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:19,764 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:19,764 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:19,765 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:19,765 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000018_1
2019-02-25 16:05:19,765 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:19,766 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,766 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,766 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:19,766 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000018_2 to list of failed maps
2019-02-25 16:05:19,775 INFO [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000081 asked for a task
2019-02-25 16:05:19,775 INFO [IPC Server handler 28 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000081 given task: attempt_1550090358635_0074_m_000016_2
2019-02-25 16:05:19,780 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:19,781 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:19,784 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:19,786 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:19,790 INFO [IPC Server handler 24 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000079 asked for a task
2019-02-25 16:05:19,790 INFO [IPC Server handler 24 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000079 given task: attempt_1550090358635_0074_m_000015_2
2019-02-25 16:05:19,790 INFO [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000078 asked for a task
2019-02-25 16:05:19,790 INFO [IPC Server handler 26 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000078 given task: attempt_1550090358635_0074_m_000019_2
2019-02-25 16:05:19,793 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:19,793 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000074 asked for a task
2019-02-25 16:05:19,793 INFO [IPC Server handler 0 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000074 given task: attempt_1550090358635_0074_m_000028_3
2019-02-25 16:05:19,796 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000077 asked for a task
2019-02-25 16:05:19,796 INFO [IPC Server handler 1 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000077 given task: attempt_1550090358635_0074_m_000026_3
2019-02-25 16:05:19,802 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000075 asked for a task
2019-02-25 16:05:19,802 INFO [IPC Server handler 2 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000075 given task: attempt_1550090358635_0074_m_000030_3
2019-02-25 16:05:19,809 INFO [IPC Server handler 4 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000002_1 is : 0.0
2019-02-25 16:05:19,814 FATAL [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000002_1 - exited : java.io.IOException: map failure for key 'GCF_000208635.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,814 INFO [IPC Server handler 3 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000002_1: Error: java.io.IOException: map failure for key 'GCF_000208635.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000002_1: Error: java.io.IOException: map failure for key 'GCF_000208635.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,814 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_1 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:19,814 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000068 taskAttempt attempt_1550090358635_0074_m_000002_1
2019-02-25 16:05:19,814 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000002_1
2019-02-25 16:05:19,814 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:19,816 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_1 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:19,817 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:19,817 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000002_1
2019-02-25 16:05:19,817 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_1 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:19,818 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,818 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:19,818 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:19,818 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000002_2 to list of failed maps
2019-02-25 16:05:19,869 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:19,874 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:19,879 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000073 asked for a task
2019-02-25 16:05:19,879 INFO [IPC Server handler 5 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000073 given task: attempt_1550090358635_0074_m_000006_1
2019-02-25 16:05:19,883 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000080 asked for a task
2019-02-25 16:05:19,883 INFO [IPC Server handler 7 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000080 given task: attempt_1550090358635_0074_m_000009_2
2019-02-25 16:05:19,886 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:19,896 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1550090358635_0074_m_000076 asked for a task
2019-02-25 16:05:19,896 INFO [IPC Server handler 6 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1550090358635_0074_m_000076 given task: attempt_1550090358635_0074_m_000031_3
2019-02-25 16:05:20,604 INFO [IPC Server handler 9 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000019_2 is : 0.0
2019-02-25 16:05:20,609 FATAL [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000019_2 - exited : java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,609 INFO [IPC Server handler 8 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000019_2: Error: java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000019_2: Error: java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,609 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:20,609 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000078 taskAttempt attempt_1550090358635_0074_m_000019_2
2019-02-25 16:05:20,609 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000019_2
2019-02-25 16:05:20,609 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:20,612 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:20,612 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,613 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000019_2
2019-02-25 16:05:20,613 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:20,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,614 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_3 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:20,614 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000019_3 to list of failed maps
2019-02-25 16:05:20,665 INFO [IPC Server handler 14 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000015_2 is : 0.0
2019-02-25 16:05:20,670 FATAL [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000015_2 - exited : java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,670 INFO [IPC Server handler 15 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000015_2: Error: java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000015_2: Error: java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,670 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:20,670 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000079 taskAttempt attempt_1550090358635_0074_m_000015_2
2019-02-25 16:05:20,670 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000015_2
2019-02-25 16:05:20,670 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:20,671 INFO [IPC Server handler 17 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000016_2 is : 0.0
2019-02-25 16:05:20,672 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:1 ScheduledMaps:19 ScheduledReds:0 AssignedMaps:19 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:83 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:20,673 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:20,673 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,674 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000015_2
2019-02-25 16:05:20,674 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:20,674 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,674 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,674 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_3 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1550090358635_0074: ask=1 release= 0 newContainers=7 finishedContainers=6 resourcelimit=<memory:422272, vCores:1> knownNMs=4
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000072
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000068
2019-02-25 16:05:20,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000017_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000069
2019-02-25 16:05:20,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000002_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000070
2019-02-25 16:05:20,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000010_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000078
2019-02-25 16:05:20,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000024_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1550090358635_0074_01_000071
2019-02-25 16:05:20,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000019_2: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 7
2019-02-25 16:05:20,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000018_1: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000087, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000087 to attempt_1550090358635_0074_m_000003_2
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000088, NodeId: r386.pvt.bridges.psc.edu:34535, NodeHttpAddress: r386.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.134:34535 }, ] to fast fail map
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000088 to attempt_1550090358635_0074_m_000022_2
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000089, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000089 to attempt_1550090358635_0074_m_000004_2
2019-02-25 16:05:20,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000090, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000090 to attempt_1550090358635_0074_m_000005_2
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000091, NodeId: r385.pvt.bridges.psc.edu:41196, NodeHttpAddress: r385.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.133:41196 }, ] to fast fail map
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000091 to attempt_1550090358635_0074_m_000007_2
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000092, NodeId: r388.pvt.bridges.psc.edu:35791, NodeHttpAddress: r388.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.136:35791 }, ] to fast fail map
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:20,675 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000092 to attempt_1550090358635_0074_m_000008_2
2019-02-25 16:05:20,675 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:20,676 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: container_1550090358635_0074_01_000093, NodeId: r389.pvt.bridges.psc.edu:46464, NodeHttpAddress: r389.pvt.bridges.psc.edu:8042, Resource: <memory:5024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.4.217.137:46464 }, ] to fast fail map
2019-02-25 16:05:20,676 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned from earlierFailedMaps
2019-02-25 16:05:20,676 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1550090358635_0074_01_000093 to attempt_1550090358635_0074_m_000014_2
2019-02-25 16:05:20,676 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=<memory:422272, vCores:1>
2019-02-25 16:05:20,676 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 2
2019-02-25 16:05:20,676 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:1 ScheduledMaps:12 ScheduledReds:0 AssignedMaps:20 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:90 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:20,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r386.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,676 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000015_3 to list of failed maps
2019-02-25 16:05:20,676 FATAL [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000016_2 - exited : java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:20,676 INFO [IPC Server handler 18 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000016_2: Error: java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:20,676 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:20,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:20,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:20,677 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000087 taskAttempt attempt_1550090358635_0074_m_000003_2
2019-02-25 16:05:20,677 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000003_2
2019-02-25 16:05:20,677 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:20,677 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r389.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,678 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2019-02-25 16:05:20,678 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000016_2: Error: java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,678 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000088 taskAttempt attempt_1550090358635_0074_m_000022_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000022_2
2019-02-25 16:05:20,678 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_2 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:20,678 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000089 taskAttempt attempt_1550090358635_0074_m_000004_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000090 taskAttempt attempt_1550090358635_0074_m_000005_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000092 taskAttempt attempt_1550090358635_0074_m_000008_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000093 taskAttempt attempt_1550090358635_0074_m_000014_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1550090358635_0074_01_000091 taskAttempt attempt_1550090358635_0074_m_000007_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000004_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000007_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:20,678 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000014_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000081 taskAttempt attempt_1550090358635_0074_m_000016_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000008_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1550090358635_0074_m_000005_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000016_2
2019-02-25 16:05:20,678 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:20,679 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:20,679 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:20,679 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:20,680 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:20,680 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000003_2 : 13562
2019-02-25 16:05:20,680 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:20,680 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000003_2] using containerId: [container_1550090358635_0074_01_000087 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:20,680 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:20,680 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000022_2 : 13562
2019-02-25 16:05:20,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_2 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:20,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000022_2] using containerId: [container_1550090358635_0074_01_000088 on NM: [r386.pvt.bridges.psc.edu:34535]
2019-02-25 16:05:20,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:20,681 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,681 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000005_2 : 13562
2019-02-25 16:05:20,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000005_2] using containerId: [container_1550090358635_0074_01_000090 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:20,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:20,681 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000016_2
2019-02-25 16:05:20,681 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_2 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:20,682 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000014_2 : 13562
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r385.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved r388.pvt.bridges.psc.edu to /default-rack
2019-02-25 16:05:20,682 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000008_2 : 13562
2019-02-25 16:05:20,682 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000007_2 : 13562
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000014_2] using containerId: [container_1550090358635_0074_01_000093 on NM: [r389.pvt.bridges.psc.edu:46464]
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:20,682 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1550090358635_0074_m_000004_2 : 13562
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_3 TaskAttempt Transitioned from NEW to UNASSIGNED
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000008_2] using containerId: [container_1550090358635_0074_01_000092 on NM: [r388.pvt.bridges.psc.edu:35791]
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000007_2] using containerId: [container_1550090358635_0074_01_000091 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1550090358635_0074_m_000004_2] using containerId: [container_1550090358635_0074_01_000089 on NM: [r385.pvt.bridges.psc.edu:41196]
2019-02-25 16:05:20,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2019-02-25 16:05:20,682 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1550090358635_0074_m_000016_3 to list of failed maps
2019-02-25 16:05:20,700 INFO [IPC Server handler 16 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000030_3 is : 0.0
2019-02-25 16:05:20,700 INFO [IPC Server handler 20 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000026_3 is : 0.0
2019-02-25 16:05:20,704 FATAL [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000030_3 - exited : java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,705 INFO [IPC Server handler 19 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_3: Error: java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000030_3: Error: java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,705 FATAL [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000026_3 - exited : java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,705 INFO [IPC Server handler 21 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_3: Error: java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_3 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:20,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000026_3: Error: java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,705 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_3 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:20,705 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000075 taskAttempt attempt_1550090358635_0074_m_000030_3
2019-02-25 16:05:20,705 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000030_3
2019-02-25 16:05:20,705 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000077 taskAttempt attempt_1550090358635_0074_m_000026_3
2019-02-25 16:05:20,705 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000026_3
2019-02-25 16:05:20,705 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:20,705 INFO [IPC Server handler 23 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1550090358635_0074_m_000028_3 is : 0.0
2019-02-25 16:05:20,705 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:20,707 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_3 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:20,707 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,708 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_3 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:20,708 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,708 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000030_3
2019-02-25 16:05:20,708 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000030_3 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:20,708 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000026_3
2019-02-25 16:05:20,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000030 Task Transitioned from RUNNING to FAILED
2019-02-25 16:05:20,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000026_3 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:20,710 FATAL [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1550090358635_0074_m_000028_3 - exited : java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,710 INFO [IPC Server handler 25 on 40283] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_3: Error: java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1
2019-02-25 16:05:20,710 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Job failed as tasks failed. failedMaps:1 failedReduces:0
2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1550090358635_0074Job Transitioned from RUNNING to FAIL_WAIT
2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000026 Task Transitioned from RUNNING to FAILED
2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1550090358635_0074_m_000028_3: Error: java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_3 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000000 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000001 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000002 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000003 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000004 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,711 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000005 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000006 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000007 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000008 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000009 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000010 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000011 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000012 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000013 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000014 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000015 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000016 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000017 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000018 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000019 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000020 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000021 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000022 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000023 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000024 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000025 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000027 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000028 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000029 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000031 Task Transitioned from RUNNING to KILL_WAIT
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_r_000000 Task Transitioned from SCHEDULED to KILL_WAIT
2019-02-25 16:05:20,712 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000074 taskAttempt attempt_1550090358635_0074_m_000028_3
2019-02-25 16:05:20,712 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000028_3
2019-02-25 16:05:20,712 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,712 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000001_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000002_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_1 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000010_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000011_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000012_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000013_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,713 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000015_3 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000016_3 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000017_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000018_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000019_3 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000020_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000023_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000024_2 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_3 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_3 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_3 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_r_000000_0 TaskAttempt Transitioned from UNASSIGNED to KILLED
2019-02-25 16:05:20,714 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,714 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000086 taskAttempt attempt_1550090358635_0074_m_000000_2
2019-02-25 16:05:20,714 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000000_2
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000001 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,714 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:20,714 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000002 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,714 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000010 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,714 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000089 taskAttempt attempt_1550090358635_0074_m_000004_2
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000011 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000090 taskAttempt attempt_1550090358635_0074_m_000005_2
2019-02-25 16:05:20,714 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000087 taskAttempt attempt_1550090358635_0074_m_000003_2
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000012 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000005_2
2019-02-25 16:05:20,715 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000092 taskAttempt attempt_1550090358635_0074_m_000008_2
2019-02-25 16:05:20,715 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000013 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000080 taskAttempt attempt_1550090358635_0074_m_000009_2
2019-02-25 16:05:20,715 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000091 taskAttempt attempt_1550090358635_0074_m_000007_2
2019-02-25 16:05:20,715 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000007_2
2019-02-25 16:05:20,715 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000073 taskAttempt attempt_1550090358635_0074_m_000006_1
2019-02-25 16:05:20,715 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000004_2
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000006_1
2019-02-25 16:05:20,715 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000093 taskAttempt attempt_1550090358635_0074_m_000014_2
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000015 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000009_2
2019-02-25 16:05:20,715 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000008_2
2019-02-25 16:05:20,715 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000003_2
2019-02-25 16:05:20,715 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:20,715 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000014_2
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000016 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000017 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000018 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000019 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000020 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000023 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000083 taskAttempt attempt_1550090358635_0074_m_000021_2
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000021_2
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000024 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,715 INFO [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
2019-02-25 16:05:20,715 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_r_000000 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,716 ERROR [Thread-52] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Could not deallocate container for task attemptId attempt_1550090358635_0074_r_000000_0
2019-02-25 16:05:20,716 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_3 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2019-02-25 16:05:20,716 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:20,716 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,716 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:20,716 INFO [ContainerLauncher #8] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:20,717 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000028_3
2019-02-25 16:05:20,717 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000028_3 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2019-02-25 16:05:20,717 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000028 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,717 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:20,717 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:20,717 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000085 taskAttempt attempt_1550090358635_0074_m_000027_3
2019-02-25 16:05:20,717 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,718 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000027_3
2019-02-25 16:05:20,717 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000082 taskAttempt attempt_1550090358635_0074_m_000029_3
2019-02-25 16:05:20,717 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000088 taskAttempt attempt_1550090358635_0074_m_000022_2
2019-02-25 16:05:20,717 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000084 taskAttempt attempt_1550090358635_0074_m_000025_2
2019-02-25 16:05:20,718 INFO [ContainerLauncher #7] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000022_2
2019-02-25 16:05:20,718 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000029_3
2019-02-25 16:05:20,718 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,718 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r389.pvt.bridges.psc.edu:46464
2019-02-25 16:05:20,718 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1550090358635_0074_01_000076 taskAttempt attempt_1550090358635_0074_m_000031_3
2019-02-25 16:05:20,718 INFO [ContainerLauncher #4] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000025_2
2019-02-25 16:05:20,718 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,718 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1550090358635_0074_m_000031_3
2019-02-25 16:05:20,718 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,718 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,718 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,718 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,718 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,718 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,718 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,718 INFO [ContainerLauncher #0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r388.pvt.bridges.psc.edu:35791
2019-02-25 16:05:20,718 INFO [ContainerLauncher #4] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:20,719 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000003_2
2019-02-25 16:05:20,719 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000014_2
2019-02-25 16:05:20,719 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000009_2
2019-02-25 16:05:20,719 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000000_2
2019-02-25 16:05:20,719 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000005_2
2019-02-25 16:05:20,719 INFO [ContainerLauncher #9] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r385.pvt.bridges.psc.edu:41196
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000003_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000014_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000009_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000000_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_1 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000005_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,719 INFO [ContainerLauncher #7] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000003 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000014 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000009 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000000 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,719 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,719 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : r386.pvt.bridges.psc.edu:34535
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000005 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,719 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,720 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,720 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_3 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,720 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000006_1
2019-02-25 16:05:20,720 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,720 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,720 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000006_1 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000006 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,720 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000008_2
2019-02-25 16:05:20,720 INFO [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_3 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000008_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000008 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,720 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000021_2
2019-02-25 16:05:20,720 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,720 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000021_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,721 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000004_2
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000021 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,721 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000031_3
2019-02-25 16:05:20,721 WARN [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000007_2
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000004_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,721 WARN [CommitterEvent Processor #3] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000025_2
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000031_3 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000004 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,721 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000029_3
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000007_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000025_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000031 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000007 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000029_3 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_2 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000025 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_3 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2019-02-25 16:05:20,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000029 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,722 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,722 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2019-02-25 16:05:20,722 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000027_3
2019-02-25 16:05:20,722 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000027_3 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,722 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000022_2
2019-02-25 16:05:20,722 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000027 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,722 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1550090358635_0074_m_000022_2 TaskAttempt Transitioned from KILL_TASK_CLEANUP to KILLED
2019-02-25 16:05:20,722 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1550090358635_0074_m_000022 Task Transitioned from KILL_WAIT to KILLED
2019-02-25 16:05:20,723 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1550090358635_0074Job Transitioned from FAIL_WAIT to FAIL_ABORT
2019-02-25 16:05:20,723 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_ABORT
2019-02-25 16:05:20,747 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:20,752 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:20,754 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1550090358635_0074Job Transitioned from FAIL_ABORT to FAILED
2019-02-25 16:05:20,754 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
2019-02-25 16:05:20,754 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2019-02-25 16:05:20,755 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: RMCommunicator notified that shouldUnregistered is: true
2019-02-25 16:05:20,755 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2019-02-25 16:05:20,755 INFO [Thread-242] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2019-02-25 16:05:20,755 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2019-02-25 16:05:20,755 INFO [Thread-242] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0
2019-02-25 16:05:20,767 INFO [Socket Reader #1 for port 40283] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1550090358635_0074 (auth:SIMPLE)
2019-02-25 16:05:20,796 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/hbagheri/.staging/job_1550090358635_0074/job_1550090358635_0074_1.jhist to hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074-1551128698035-hbagheri-Asm%3A+%2Fuser%2Fhbagheri%2Ftmp%2FasmFeb25OUTUT-1551128720710-0-0-FAILED-default-1551128701558.jhist_tmp
2019-02-25 16:05:20,860 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074-1551128698035-hbagheri-Asm%3A+%2Fuser%2Fhbagheri%2Ftmp%2FasmFeb25OUTUT-1551128720710-0-0-FAILED-default-1551128701558.jhist_tmp
2019-02-25 16:05:20,868 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/hbagheri/.staging/job_1550090358635_0074/job_1550090358635_0074_1_conf.xml to hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074_conf.xml_tmp
2019-02-25 16:05:20,893 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074_conf.xml_tmp
2019-02-25 16:05:20,911 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074.summary_tmp to hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074.summary
2019-02-25 16:05:20,918 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074_conf.xml_tmp to hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074_conf.xml
2019-02-25 16:05:20,926 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074-1551128698035-hbagheri-Asm%3A+%2Fuser%2Fhbagheri%2Ftmp%2FasmFeb25OUTUT-1551128720710-0-0-FAILED-default-1551128701558.jhist_tmp to hdfs://r383.opa.bridges.psc.edu:8020/tmp/hadoop-yarn/staging/history/done_intermediate/hbagheri/job_1550090358635_0074-1551128698035-hbagheri-Asm%3A+%2Fuser%2Fhbagheri%2Ftmp%2FasmFeb25OUTUT-1551128720710-0-0-FAILED-default-1551128701558.jhist
2019-02-25 16:05:20,926 INFO [Thread-242] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2019-02-25 16:05:20,929 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Setting job diagnostics to Task failed task_1550090358635_0074_m_000030
Job failed as tasks failed. failedMaps:1 failedReduces:0

2019-02-25 16:05:20,929 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: History url is http://r385.pvt.bridges.psc.edu:19888/jobhistory/job/job_1550090358635_0074
2019-02-25 16:05:20,933 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Waiting for application to be successfully unregistered.
2019-02-25 16:05:21,934 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:1 ScheduledMaps:12 ScheduledReds:0 AssignedMaps:20 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:90 ContRel:0 HostLocal:32 RackLocal:0
2019-02-25 16:05:21,935 INFO [Thread-242] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://r383.opa.bridges.psc.edu:8020/ /tmp/hadoop-yarn/staging/hbagheri/.staging/job_1550090358635_0074
2019-02-25 16:05:21,943 INFO [Thread-242] org.apache.hadoop.ipc.Server: Stopping server on 40283
2019-02-25 16:05:21,944 INFO [IPC Server listener on 40283] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 40283
2019-02-25 16:05:21,945 INFO [TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted
2019-02-25 16:05:21,945 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
End of LogType:syslog



Container: container_1550090358635_0074_01_000034 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900488375.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:04,943 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:04,998 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:04,999 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:05,007 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:05,007 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:05,183 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:05,378 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:05,534 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:05,907 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:05,918 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:05,938 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:05,939 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:05,939 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:05,939 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:05,939 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:05,939 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:05,939 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:05,939 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:05,939 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:06,082 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:93000000+2535356
2019-02-25 16:05:06,131 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:06,131 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:06,131 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:06,131 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:06,131 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:06,139 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:06,159 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:06,160 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:06,221 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:06,223 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:06,228 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:06,231 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,234 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:06,238 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000031_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000067 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000935645.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:17,411 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:17,466 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:17,467 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:17,475 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:17,475 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:17,651 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:17,840 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:17,988 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:18,326 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:18,337 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:18,359 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:18,360 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:18,360 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:18,360 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:18,360 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:18,360 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:18,360 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:18,360 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:18,361 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:18,499 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:36000000+3000000
2019-02-25 16:05:18,551 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:18,551 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:18,551 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:18,551 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:18,551 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:18,558 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:18,576 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:18,576 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:18,661 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,662 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:18,668 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:18,671 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000935645.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,673 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:18,677 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000012_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000031 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003991285.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:04,926 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:04,981 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:04,981 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:04,989 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:04,990 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:05,158 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:05,347 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:05,496 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:05,880 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:05,889 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:05,912 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:05,912 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:05,912 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:05,913 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:05,913 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:05,913 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:05,913 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:05,913 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:05,913 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:06,058 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:84000000+3000000
2019-02-25 16:05:06,098 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:06,098 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:06,098 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:06,098 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:06,098 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:06,105 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:06,126 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:06,127 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:06,180 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:06,182 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:06,188 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:06,190 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,193 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:06,197 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000028_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000032 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900032835.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:04,950 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:05,006 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:05,006 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:05,014 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:05,014 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:05,187 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:05,370 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:05,525 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:05,909 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:05,920 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:05,944 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:05,944 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:05,945 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:05,945 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:05,945 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:05,945 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:05,945 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:05,945 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:05,945 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:06,086 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:87000000+3000000
2019-02-25 16:05:06,143 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:06,143 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:06,143 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:06,143 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:06,143 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:06,151 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:06,172 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:06,172 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:06,231 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:06,233 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:06,238 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:06,241 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,244 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:06,248 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000029_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000029 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003334585.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:04,893 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:04,950 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:04,950 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:04,958 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:04,959 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:05,130 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:05,327 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:05,475 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:05,859 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:05,869 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:05,892 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:05,892 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:05,892 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:05,892 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:05,893 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:05,893 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:05,893 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:05,893 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:05,893 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:06,044 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:78000000+3000000
2019-02-25 16:05:06,085 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:06,085 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:06,085 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:06,085 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:06,085 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:06,092 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:06,113 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:06,114 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:06,175 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:06,176 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:06,182 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:06,185 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,187 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:06,191 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000026_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000030 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003610085.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:04,934 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:04,990 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:04,990 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:04,998 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:04,998 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:05,169 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:05,361 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:05,513 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:05,913 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:05,924 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:05,951 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:05,951 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:05,951 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:05,951 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:05,951 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:05,952 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:05,952 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:05,952 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:05,952 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:06,112 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:81000000+3000000
2019-02-25 16:05:06,153 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:06,153 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:06,153 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:06,153 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:06,153 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:06,161 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:06,181 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:06,182 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:06,243 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:06,245 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:06,251 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:06,254 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:06,257 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:06,260 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000027_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000075 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900159185.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:19,448 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:19,504 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:19,504 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:19,513 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:19,513 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:19,682 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:19,869 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:20,016 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:20,367 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:20,377 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:20,404 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:20,405 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:20,405 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:20,405 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:20,405 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:20,405 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:20,405 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:20,406 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:20,406 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:20,549 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:90000000+3000000
2019-02-25 16:05:20,600 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:20,600 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:20,600 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:20,600 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:20,600 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:20,608 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:20,630 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:20,630 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:20,688 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,690 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:20,696 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:20,698 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,700 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:20,704 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000030_3
End of LogType:syslog



Container: container_1550090358635_0074_01_000071 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001682715.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:18,391 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:18,446 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:18,446 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:18,454 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:18,454 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:18,619 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:18,808 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:18,956 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:19,304 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:19,314 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:19,340 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:19,341 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:19,341 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:19,341 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:19,341 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:19,341 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:19,341 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:19,342 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:19,342 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:19,482 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:54000000+3000000
2019-02-25 16:05:19,538 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:19,538 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:19,538 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:19,538 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:19,538 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:19,545 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:19,564 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:19,564 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:19,744 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:19,746 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:19,752 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:19,754 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001682715.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,756 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:19,760 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000018_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000051 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002155895.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:15,369 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:15,423 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:15,423 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:15,431 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:15,432 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:15,600 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:15,787 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:15,937 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:16,293 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:16,303 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:16,325 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:16,325 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:16,325 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:16,325 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:16,325 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:16,326 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:16,326 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:16,326 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:16,326 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:16,472 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:63000000+3000000
2019-02-25 16:05:16,513 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:16,513 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:16,513 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:16,513 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:16,513 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:16,521 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:16,540 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:16,541 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:16,601 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:16,603 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:16,608 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:16,611 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002155895.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,613 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:16,617 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000021_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000082 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:808
Log Contents:
2019-02-25 16:05:20,407 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:20,463 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:20,463 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:20,472 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:20,472 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:20,635 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
End of LogType:syslog



Container: container_1550090358635_0074_01_000081 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001466015.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:19,425 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:19,480 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:19,480 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:19,488 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:19,488 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:19,656 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:19,843 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:19,988 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:20,343 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:20,353 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:20,375 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:20,375 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:20,376 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:20,376 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:20,376 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:20,376 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:20,376 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:20,376 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:20,376 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:20,521 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:48000000+3000000
2019-02-25 16:05:20,569 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:20,569 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:20,569 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:20,569 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:20,569 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:20,577 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:20,598 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:20,599 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:20,660 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,661 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:20,667 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:20,670 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,671 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:20,675 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000016_2
End of LogType:syslog



Container: container_1550090358635_0074_01_000047 on r385.pvt.bridges.psc.edu_41196_1551128728536
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000691865.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:28 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:14,375 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:14,429 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:14,429 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:14,437 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:14,437 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:14,592 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:14,768 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:14,911 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:15,251 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:15,261 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:15,284 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:15,284 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:15,284 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:15,285 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:15,285 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 489
2019-02-25 16:05:15,285 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 490
2019-02-25 16:05:15,285 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 491
2019-02-25 16:05:15,285 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 492
2019-02-25 16:05:15,285 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 493
2019-02-25 16:05:15,429 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:27000000+3000000
2019-02-25 16:05:15,484 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:15,484 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:15,484 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:15,485 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:15,485 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:15,492 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:15,510 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:15,511 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:15,575 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:15,576 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:15,582 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:15,585 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000691865.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,587 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:15,590 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000009_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000058 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000622325.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:16,400 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:16,455 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:16,456 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:16,463 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:16,464 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:16,635 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:16,814 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:16,959 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:17,324 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:17,334 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:17,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:17,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:17,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:17,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:17,356 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:17,357 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:17,357 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:17,357 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:17,357 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:17,507 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:24000000+3000000
2019-02-25 16:05:17,558 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:17,558 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:17,558 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:17,558 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:17,558 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:17,567 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:17,606 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:17,607 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:17,754 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,756 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:17,761 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:17,764 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000622325.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,766 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:17,769 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000008_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000057 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000323305.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:16,410 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:16,464 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:16,465 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:16,473 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:16,473 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:16,640 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:16,830 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:16,976 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:17,342 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:17,353 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:17,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:17,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:17,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:17,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:17,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:17,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:17,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:17,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:17,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:17,530 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:12000000+3000000
2019-02-25 16:05:17,582 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:17,582 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:17,582 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:17,583 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:17,583 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:17,590 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:17,625 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:17,626 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:17,685 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,686 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:17,692 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:17,695 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000323305.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,697 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:17,701 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000004_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000085 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:808
Log Contents:
2019-02-25 16:05:20,420 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:20,476 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:20,477 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:20,485 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:20,485 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:20,654 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
End of LogType:syslog



Container: container_1550090358635_0074_01_000088 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:syslog



Container: container_1550090358635_0074_01_000066 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002708555.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:17,412 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:17,469 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:17,469 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:17,477 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:17,477 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:17,653 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:17,845 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:17,992 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:18,351 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:18,361 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:18,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:18,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:18,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:18,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:18,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:18,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:18,390 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:18,390 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:18,390 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:18,533 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:69000000+3000000
2019-02-25 16:05:18,573 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:18,573 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:18,573 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:18,573 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:18,573 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:18,581 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:18,617 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:18,617 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:18,676 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,678 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:18,683 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:18,686 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002708555.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,688 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:18,692 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000023_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000062 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002007485.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:17,421 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:17,477 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:17,477 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:17,485 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:17,485 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:17,651 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:17,843 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:17,992 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:18,359 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:18,370 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:18,396 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:18,396 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:18,396 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:18,397 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:18,397 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:18,397 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:18,397 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:18,397 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:18,398 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:18,541 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:60000000+3000000
2019-02-25 16:05:18,591 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:18,591 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:18,591 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:18,591 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:18,591 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:18,599 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:18,633 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:18,634 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:18,736 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,738 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:18,744 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:18,747 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002007485.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,749 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:18,752 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000020_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000043 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900159185.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:11,367 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:11,420 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:11,420 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:11,428 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:11,428 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:11,590 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:11,771 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:11,921 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:12,257 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:12,267 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:12,289 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:12,289 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:12,290 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:12,290 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:12,290 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:12,290 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:12,290 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:12,290 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:12,290 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:12,432 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:90000000+3000000
2019-02-25 16:05:12,473 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:12,473 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:12,473 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:12,473 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:12,473 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:12,481 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:12,516 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:12,516 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:12,572 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:12,574 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:12,579 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:12,582 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:12,584 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:12,588 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000030_2
End of LogType:syslog



Container: container_1550090358635_0074_01_000074 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003991285.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:19,432 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:19,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:19,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:19,495 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:19,495 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:19,671 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:19,861 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:20,009 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:20,378 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:20,388 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:20,410 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:20,410 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:20,410 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:20,410 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:20,410 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:20,410 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:20,410 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:20,410 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:20,411 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:20,554 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:84000000+3000000
2019-02-25 16:05:20,599 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:20,599 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:20,599 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:20,599 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:20,599 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:20,607 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:20,645 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:20,645 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:20,694 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,696 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:20,701 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:20,704 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,706 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:20,710 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000028_3
End of LogType:syslog



Container: container_1550090358635_0074_01_000041 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003610085.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:10,329 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:10,379 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:10,379 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:10,386 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:10,386 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:10,535 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:10,705 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,860 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,216 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,226 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,246 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:11,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:11,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:11,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:11,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:11,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:11,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:11,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:11,248 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:11,370 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:81000000+3000000
2019-02-25 16:05:11,416 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,416 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,416 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,416 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,416 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,424 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,458 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,458 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,517 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,519 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,524 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,527 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,530 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,534 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000027_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000039 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900488375.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:09,336 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:09,391 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:09,391 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:09,399 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:09,399 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,553 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,731 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,879 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,240 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:10,251 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:10,279 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:10,279 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:10,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:10,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:10,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:10,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:10,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:10,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:10,281 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:10,428 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:93000000+2535356
2019-02-25 16:05:10,485 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:10,486 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:10,486 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:10,486 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:10,486 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:10,493 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:10,587 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:10,587 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:10,676 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:10,678 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:10,684 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:10,687 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:10,689 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:10,693 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000031_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000037 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900159185.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:08,445 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,499 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,499 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,507 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,507 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,664 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:08,849 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,001 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:09,343 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:09,354 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:09,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:09,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:09,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:09,381 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:09,381 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:09,381 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:09,381 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:09,381 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:09,381 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:09,517 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:90000000+3000000
2019-02-25 16:05:09,572 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:09,572 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:09,572 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:09,572 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:09,573 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:09,580 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:09,616 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:09,617 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:09,671 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:09,672 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:09,677 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:09,680 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900159185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:09,684 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:09,688 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000030_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000072 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001574785.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:18,399 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:18,455 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:18,455 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:18,463 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:18,463 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:18,625 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:18,820 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:18,969 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:19,332 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:19,343 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:19,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:19,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:19,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:19,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:19,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:19,366 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:19,366 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:19,366 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:19,366 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:19,510 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:51000000+3000000
2019-02-25 16:05:19,551 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:19,551 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:19,551 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:19,551 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:19,551 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:19,558 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:19,594 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:19,594 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:19,650 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:19,651 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:19,657 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:19,660 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001574785.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,661 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:19,665 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000017_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000052 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003062915.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:15,372 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:15,427 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:15,427 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:15,435 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:15,436 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:15,605 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:15,788 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:15,937 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:16,289 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:16,299 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:16,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:16,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:16,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:16,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:16,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:16,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:16,322 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:16,322 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:16,322 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:16,467 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:75000000+3000000
2019-02-25 16:05:16,509 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:16,509 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:16,509 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:16,509 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:16,509 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:16,517 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:16,554 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:16,554 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:16,609 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:16,611 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:16,616 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:16,618 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003062915.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,621 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:16,625 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000025_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000084 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:808
Log Contents:
2019-02-25 16:05:20,426 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:20,482 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:20,482 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:20,490 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:20,490 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:20,655 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
End of LogType:syslog



Container: container_1550090358635_0074_01_000048 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001336335.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:14,372 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:14,426 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:14,426 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:14,434 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:14,434 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:14,583 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:14,759 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:14,908 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:15,246 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:15,256 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:15,278 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:15,278 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:15,278 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:15,278 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:15,278 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:15,278 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:15,278 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:15,278 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:15,279 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:15,408 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:45000000+3000000
2019-02-25 16:05:15,452 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:15,452 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:15,452 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:15,452 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:15,452 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:15,460 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:15,497 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:15,498 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:15,553 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:15,555 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:15,561 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:15,563 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,565 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:15,569 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000015_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000077 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003334585.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:19,440 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:19,495 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:19,495 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:19,503 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:19,504 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:19,675 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:19,858 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:20,010 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:20,350 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:20,360 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:20,383 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:20,530 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:78000000+3000000
2019-02-25 16:05:20,587 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:20,587 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:20,587 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:20,587 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:20,587 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:20,595 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:20,633 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:20,633 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:20,688 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,690 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:20,696 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:20,699 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,700 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:20,704 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000026_3
End of LogType:syslog



Container: container_1550090358635_0074_01_000045 on r386.pvt.bridges.psc.edu_34535_1551128727851
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900488375.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6392
Log Contents:
2019-02-25 16:05:12,362 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:12,417 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:12,417 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:12,425 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:12,425 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:12,589 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:12,764 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:12,899 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:13,210 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:13,220 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:13,246 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:13,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:13,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:13,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:13,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:13,247 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:13,248 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:13,248 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:13,248 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:13,380 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:93000000+2535356
2019-02-25 16:05:13,420 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:13,420 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:13,420 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:13,420 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:13,420 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:13,427 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:13,460 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:13,461 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:13,519 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:13,520 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:13,526 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:13,528 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900488375.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:13,530 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:13,534 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000031_2
End of LogType:syslog



Container: container_1550090358635_0074_01_000092 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1550090358635_0074_01_000026 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2565
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002901215.1
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:9185
Log Contents:
2019-02-25 16:05:08,507 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,773 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,773 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,991 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,991 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,204 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:10,019 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,377 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,229 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,264 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,326 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,326 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,326 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,326 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,327 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,327 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,327 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,327 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,327 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,479 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,483 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,538 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:72000000+3000000
2019-02-25 16:05:11,591 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,591 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,591 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,591 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,591 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,611 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,634 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,635 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,797 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,798 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,804 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,807 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002901215.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,809 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,813 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000024_0
2019-02-25 16:05:11,915 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...
2019-02-25 16:05:11,916 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.
2019-02-25 16:05:11,916 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.
End of LogType:syslog



Container: container_1550090358635_0074_01_000059 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002289615.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:16,418 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:16,474 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:16,474 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:16,482 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:16,482 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:16,658 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:16,849 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:16,995 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:17,357 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:17,368 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:17,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:17,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:17,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:17,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:17,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:17,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:17,389 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:17,390 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:17,390 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:17,474 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,477 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:17,520 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:66000000+3000000
2019-02-25 16:05:17,568 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:17,568 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:17,568 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:17,568 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:17,568 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:17,576 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:17,597 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:17,597 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:17,647 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,648 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:17,653 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:17,656 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002289615.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,658 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:17,661 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000022_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000086 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:808
Log Contents:
2019-02-25 16:05:20,403 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:20,458 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:20,458 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:20,466 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:20,466 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:20,629 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
End of LogType:syslog



Container: container_1550090358635_0074_01_000024 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2565
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002289615.1
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:9185
Log Contents:
2019-02-25 16:05:08,424 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,618 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,618 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,756 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,756 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,060 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,622 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,054 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,960 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,047 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,111 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,111 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,112 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,112 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,112 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,112 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,112 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,112 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,112 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,335 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,338 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,410 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:66000000+3000000
2019-02-25 16:05:11,463 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,464 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,464 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,464 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,464 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,473 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,505 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,506 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,597 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,598 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,607 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,610 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002289615.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,621 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,626 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000022_0
2019-02-25 16:05:11,730 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...
2019-02-25 16:05:11,730 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.
2019-02-25 16:05:11,730 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.
End of LogType:syslog



Container: container_1550090358635_0074_01_000022 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002007485.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,412 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,615 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,615 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,747 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,747 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,035 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,587 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,080 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,095 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,155 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,197 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,197 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,197 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,197 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,198 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,198 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,198 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,198 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,198 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,396 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,400 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,463 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:60000000+3000000
2019-02-25 16:05:11,506 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,506 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,506 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,506 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,506 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,515 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,543 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,543 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,703 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,704 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,710 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,713 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002007485.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,716 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,721 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000020_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000003 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000146835.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8814
Log Contents:
2019-02-25 16:05:08,331 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,554 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,554 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,668 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,668 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,943 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,573 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,021 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,098 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,190 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,237 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,237 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,237 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,237 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,237 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,237 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,237 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,238 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,238 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,390 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,394 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,483 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:3000000+3000000
2019-02-25 16:05:11,546 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,546 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,546 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,546 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,546 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,557 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,586 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,586 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,707 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,708 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,716 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,719 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000146835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,722 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,727 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000001_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000011 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000691865.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,169 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,490 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,490 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,623 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,624 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,881 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,412 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,827 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,696 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:10,708 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:10,844 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:10,845 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:10,845 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:10,845 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:10,845 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:10,845 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:10,845 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:10,845 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:10,845 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:10,991 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:10,995 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,054 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:27000000+3000000
2019-02-25 16:05:11,126 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,126 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,126 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,126 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,126 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,144 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,179 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,179 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,298 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,299 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,310 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,313 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000691865.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,322 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,329 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000009_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000073 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:226
Log Contents:
log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapred.MapTask).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6466
Log Contents:
2019-02-25 16:05:19,528 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:19,582 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:19,583 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:19,590 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:19,590 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:19,758 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:19,946 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:20,095 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:20,474 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:20,484 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:20,504 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:20,504 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:20,504 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:20,504 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:20,504 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:20,504 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:20,505 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:20,505 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:20,505 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:20,591 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,594 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:20,641 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:18000000+3000000
2019-02-25 16:05:20,694 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:20,694 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:20,694 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:20,694 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:20,695 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:20,702 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:20,724 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:20,724 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
End of LogType:syslog



Container: container_1550090358635_0074_01_000009 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000517545.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:07,955 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,418 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,418 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,524 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,524 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,808 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,364 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,725 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,524 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:10,696 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:10,773 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:10,773 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:10,773 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:10,774 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:10,774 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:10,774 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:10,774 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:10,774 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:10,774 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,027 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,031 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,129 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:21000000+3000000
2019-02-25 16:05:11,181 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,181 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,181 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,181 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,181 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,195 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,262 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,263 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,529 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,530 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,566 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,569 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000517545.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,572 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,579 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000007_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000007 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000390385.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,280 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,515 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,515 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,641 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,641 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,932 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,479 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,904 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,965 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,062 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,110 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,110 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,111 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,111 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,111 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,111 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,111 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,111 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,112 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,332 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,336 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,404 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:15000000+3000000
2019-02-25 16:05:11,456 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,456 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,456 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,456 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,456 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,465 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,491 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,492 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,653 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,654 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,661 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,664 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000390385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,666 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,670 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000005_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000005 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2565
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000237025.1
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:9184
Log Contents:
2019-02-25 16:05:08,385 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,599 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,599 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,715 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,716 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,074 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,616 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,094 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,071 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,091 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,124 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,125 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,125 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,125 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,125 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,125 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,125 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,126 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,126 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,317 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,320 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,388 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:9000000+3000000
2019-02-25 16:05:11,442 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,442 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,442 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,442 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,442 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,452 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,474 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,474 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,549 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,549 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,582 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,585 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000237025.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,588 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,592 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000003_0
2019-02-25 16:05:11,695 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...
2019-02-25 16:05:11,695 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.
2019-02-25 16:05:11,695 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.
End of LogType:syslog



Container: container_1550090358635_0074_01_000019 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2565
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001574785.1
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:9185
Log Contents:
2019-02-25 16:05:08,437 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,644 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,644 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,792 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,792 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,086 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,708 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,116 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,207 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,326 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,361 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,362 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,362 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,362 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,598 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,601 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,663 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:51000000+3000000
2019-02-25 16:05:11,718 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,718 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,718 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,718 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,718 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,726 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,750 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,750 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,809 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,809 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,815 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,818 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001574785.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,820 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,824 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000017_0
2019-02-25 16:05:11,926 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...
2019-02-25 16:05:11,926 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.
2019-02-25 16:05:11,926 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.
End of LogType:syslog



Container: container_1550090358635_0074_01_000017 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001336335.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,021 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,474 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,474 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,565 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,565 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,817 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,379 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,793 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,805 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:10,828 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:10,894 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:10,894 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:10,894 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:10,895 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:10,895 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:10,895 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:10,895 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:10,895 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:10,895 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,085 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,089 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,152 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:45000000+3000000
2019-02-25 16:05:11,197 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,197 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,197 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,197 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,197 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,206 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,265 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,265 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,438 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,439 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,454 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,458 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,461 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,465 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000015_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000050 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003610085.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:15,391 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:15,446 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:15,446 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:15,454 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:15,454 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:15,631 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:15,817 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:15,965 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:16,325 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:16,336 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:16,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:16,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:16,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:16,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:16,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:16,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:16,364 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:16,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:16,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:16,464 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:16,467 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:16,512 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:81000000+3000000
2019-02-25 16:05:16,550 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:16,550 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:16,550 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:16,550 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:16,550 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:16,557 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:16,577 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:16,578 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:16,633 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:16,634 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:16,640 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:16,643 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003610085.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,644 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:16,648 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000027_2
End of LogType:syslog



Container: container_1550090358635_0074_01_000015 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001083795.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,480 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,719 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,719 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,898 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,898 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,144 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,869 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,216 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,161 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,185 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,239 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,239 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,240 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,240 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,240 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,240 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,240 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,240 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,240 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,418 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,421 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,502 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:39000000+3000000
2019-02-25 16:05:11,552 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,552 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,552 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,552 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,552 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,561 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,596 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,596 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,724 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,724 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,734 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,738 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001083795.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,740 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,745 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000013_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000013 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000767605.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,467 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,702 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,702 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,859 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,860 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,122 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,731 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,219 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,136 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,208 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,251 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,252 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,252 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,252 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,252 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,252 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,252 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,253 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,253 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,446 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,450 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,518 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:33000000+3000000
2019-02-25 16:05:11,560 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,560 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,560 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,560 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,560 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,568 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,602 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,602 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,737 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,737 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,744 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,747 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000767605.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,749 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,753 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000011_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000046 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001466015.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:14,383 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:14,437 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:14,437 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:14,447 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:14,447 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:14,605 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:14,778 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:14,925 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:15,282 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:15,293 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:15,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:15,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:15,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:15,321 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:15,322 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:15,322 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:15,322 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:15,322 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:15,322 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:15,423 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:15,426 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:15,471 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:48000000+3000000
2019-02-25 16:05:15,510 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:15,510 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:15,510 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:15,510 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:15,510 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:15,518 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:15,538 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:15,538 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:15,594 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:15,595 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:15,600 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:15,603 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,605 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:15,608 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000016_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000027 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003062915.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,185 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,488 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,604 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,604 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,852 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,376 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,826 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,763 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:10,815 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:10,878 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:10,878 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:10,878 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:10,878 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:10,879 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:10,879 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:10,879 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:10,879 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:10,879 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,128 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,132 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,242 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:75000000+3000000
2019-02-25 16:05:11,306 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,306 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,306 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,306 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,306 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,318 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,359 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,359 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,503 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,504 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,516 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,520 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003062915.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,541 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,561 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000025_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000025 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002708555.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,448 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,657 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,657 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,836 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,836 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,097 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,791 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,272 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,248 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,292 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,331 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,332 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,332 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,332 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,332 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,332 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,332 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,352 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,352 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,518 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,522 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,579 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:69000000+3000000
2019-02-25 16:05:11,636 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,636 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,636 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,636 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,636 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,645 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,672 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,672 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,752 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,752 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,758 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,761 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002708555.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,763 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,767 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000023_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000023 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002155895.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,307 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,557 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,557 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,680 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,681 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,985 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,590 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,987 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,927 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,004 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,072 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,072 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,072 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,072 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,073 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,073 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,073 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,073 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,073 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,238 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,241 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,325 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:63000000+3000000
2019-02-25 16:05:11,370 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,370 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,370 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,370 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,370 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,379 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,404 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,405 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,503 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,504 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,511 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,514 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002155895.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,518 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,545 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000021_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000021 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001859185.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,346 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,560 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,560 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,685 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,685 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,973 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,553 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,941 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,877 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:10,898 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:10,955 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:10,955 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:10,956 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:10,956 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:10,960 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:10,960 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:10,960 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:10,960 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:10,960 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,131 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,135 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,231 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:57000000+3000000
2019-02-25 16:05:11,329 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,329 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,329 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,329 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,329 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,369 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,394 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,395 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,483 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,484 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,495 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,499 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,502 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,507 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000019_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000054 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000517545.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:16,418 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:16,473 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:16,473 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:16,481 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:16,481 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:16,651 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:16,835 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:16,978 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:17,330 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:17,340 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:17,362 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:17,362 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:17,362 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:17,362 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:17,362 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:17,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:17,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:17,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:17,363 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:17,454 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,457 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:17,501 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:21000000+3000000
2019-02-25 16:05:17,544 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:17,545 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:17,545 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:17,545 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:17,545 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:17,552 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:17,572 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:17,572 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:17,742 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,743 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:17,749 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:17,751 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000517545.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,753 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:17,757 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000007_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000004 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000208635.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8814
Log Contents:
2019-02-25 16:05:08,251 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,493 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,493 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,627 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,628 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,894 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,412 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,839 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,990 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,054 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,101 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,101 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,101 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,101 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,101 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,101 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,101 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,102 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,102 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,314 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,319 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,409 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:6000000+3000000
2019-02-25 16:05:11,465 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,465 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,465 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,465 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,465 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,474 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,510 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,510 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,762 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,763 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,769 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,772 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000208635.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,774 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,778 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000002_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000068 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000208635.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8814
Log Contents:
2019-02-25 16:05:18,392 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:18,448 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:18,448 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:18,456 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:18,456 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:18,627 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:18,813 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:18,961 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:19,311 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:19,321 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:19,343 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:19,343 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:19,343 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:19,343 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:19,344 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:19,344 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:19,344 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:19,344 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:19,344 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:19,434 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:19,437 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:19,485 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:6000000+3000000
2019-02-25 16:05:19,534 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:19,534 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:19,534 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:19,534 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:19,534 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:19,542 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:19,564 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:19,564 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:19,798 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:19,799 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:19,804 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:19,807 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000208635.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,809 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:19,813 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000002_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000002 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000001215.4
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8808
Log Contents:
2019-02-25 16:05:08,113 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,477 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,477 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,572 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,573 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,832 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,410 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,877 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,914 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,047 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,088 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,089 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,089 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,089 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,089 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,089 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,089 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,089 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,089 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,297 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,300 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,390 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:0+3000000
2019-02-25 16:05:11,441 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,441 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,441 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,441 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,441 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,451 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,474 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,475 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,562 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,563 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,582 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,585 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000001215.4'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,598 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,614 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000000_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000064 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001083795.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:17,384 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:17,440 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:17,440 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:17,448 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:17,448 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:17,613 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:17,804 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:17,954 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:18,308 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:18,318 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:18,339 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:18,339 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:18,340 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:18,340 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:18,340 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:18,340 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:18,340 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:18,340 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:18,340 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:18,438 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,441 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:18,485 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:39000000+3000000
2019-02-25 16:05:18,523 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:18,523 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:18,523 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:18,523 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:18,523 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:18,530 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:18,550 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:18,550 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:18,605 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,606 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:18,612 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:18,615 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001083795.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,617 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:18,620 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000013_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000012 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2565
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000708245.1
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:9185
Log Contents:
2019-02-25 16:05:08,501 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,770 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,770 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,947 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,947 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,171 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,901 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,325 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,296 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,325 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,357 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,357 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,358 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,358 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,358 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,358 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,358 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,358 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,358 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,531 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,535 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,594 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:30000000+3000000
2019-02-25 16:05:11,645 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,646 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,646 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,646 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,646 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,655 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,698 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,698 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,788 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,789 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,795 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,798 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000708245.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,800 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,803 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000010_0
2019-02-25 16:05:11,906 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...
2019-02-25 16:05:11,906 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.
2019-02-25 16:05:11,906 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.
End of LogType:syslog



Container: container_1550090358635_0074_01_000076 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6466
Log Contents:
2019-02-25 16:05:19,538 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:19,594 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:19,594 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:19,602 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:19,602 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:19,774 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:19,959 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:20,105 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:20,465 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:20,476 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:20,498 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:20,498 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:20,498 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:20,498 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:20,498 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:20,498 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:20,499 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:20,499 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:20,499 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:20,592 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,595 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:20,640 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:93000000+2535356
2019-02-25 16:05:20,689 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:20,690 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:20,690 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:20,690 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:20,690 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:20,698 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:20,721 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:20,721 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
End of LogType:syslog



Container: container_1550090358635_0074_01_000010 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2565
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000622325.1
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:9185
Log Contents:
2019-02-25 16:05:08,155 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,484 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,484 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,589 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,589 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,831 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,381 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,785 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,851 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:10,961 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:10,992 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:10,992 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:10,992 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:10,992 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:10,993 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:10,993 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:10,993 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:10,993 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:10,993 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,163 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,166 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,246 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:24000000+3000000
2019-02-25 16:05:11,323 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,323 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,323 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,323 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,323 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,331 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,388 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,388 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,601 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,602 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,609 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,613 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000622325.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,616 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,622 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000008_0
2019-02-25 16:05:11,725 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...
2019-02-25 16:05:11,725 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.
2019-02-25 16:05:11,725 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.
End of LogType:syslog



Container: container_1550090358635_0074_01_000008 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000457385.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,362 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,567 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,567 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,697 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,697 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,004 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,608 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,263 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,270 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,308 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,365 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,366 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,366 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,366 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,366 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,366 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,511 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,514 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,583 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:18000000+3000000
2019-02-25 16:05:11,641 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,641 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,641 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,641 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,641 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,649 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,672 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,673 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,856 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,857 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,863 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,866 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000457385.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,868 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,872 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000006_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000006 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000323305.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,400 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,612 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,612 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,735 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,735 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,024 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,595 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,087 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,927 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,016 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,077 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,077 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,077 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,078 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,078 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,078 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,078 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,078 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,078 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,288 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,292 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,414 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:12000000+3000000
2019-02-25 16:05:11,469 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,469 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,469 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,469 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,469 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,477 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,502 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,502 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,590 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,591 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,602 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,605 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000323305.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,607 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,622 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000004_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000020 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2565
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001682715.1
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:9185
Log Contents:
2019-02-25 16:05:08,375 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,584 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,584 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,707 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,707 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,013 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,583 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,012 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,053 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,166 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,222 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,223 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,223 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,223 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,223 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,223 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,223 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,223 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,223 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,435 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,439 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,495 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:54000000+3000000
2019-02-25 16:05:11,542 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,542 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,542 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,542 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,542 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,553 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,577 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,578 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,807 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,808 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,814 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,817 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001682715.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,819 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,823 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000018_0
2019-02-25 16:05:11,926 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...
2019-02-25 16:05:11,926 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.
2019-02-25 16:05:11,926 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.
End of LogType:syslog



Container: container_1550090358635_0074_01_000018 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001466015.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,012 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,470 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,470 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,551 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,551 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,803 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,346 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,676 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,480 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:10,585 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:10,639 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:10,639 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:10,639 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:10,639 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:10,639 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:10,640 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:10,640 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:10,640 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:10,640 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:10,919 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:10,923 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:10,977 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:48000000+3000000
2019-02-25 16:05:11,049 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,049 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,049 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,049 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,049 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,058 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,082 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,083 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,232 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,232 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,240 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,244 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001466015.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,296 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,302 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000016_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000016 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001218505.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,490 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,731 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,731 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,912 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,912 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,150 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,837 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,255 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,181 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,202 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,228 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,228 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,228 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,228 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,229 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,229 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,229 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,229 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,229 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,408 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,412 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,499 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:42000000+3000000
2019-02-25 16:05:11,559 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,559 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,559 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,559 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,559 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,568 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,593 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,593 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,682 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,683 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,689 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,692 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001218505.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,696 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,701 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000014_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000080 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:226
Log Contents:
log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapred.MapTask).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:6466
Log Contents:
2019-02-25 16:05:19,520 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:19,577 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:19,577 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:19,585 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:19,585 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:19,758 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:19,948 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:20,095 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:20,474 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:20,484 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:20,506 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:20,506 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:20,507 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:20,507 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:20,507 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:20,507 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:20,507 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:20,507 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:20,507 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:20,606 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,609 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:20,654 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:27000000+3000000
2019-02-25 16:05:20,695 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:20,695 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:20,695 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:20,695 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:20,695 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:20,703 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:20,724 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:20,724 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
End of LogType:syslog



Container: container_1550090358635_0074_01_000014 on r388.pvt.bridges.psc.edu_35791_1551128727859
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000935645.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,388 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,609 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,610 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,724 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,724 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,047 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,606 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,104 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,187 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,223 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,260 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 499
2019-02-25 16:05:11,260 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 500
2019-02-25 16:05:11,260 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 501
2019-02-25 16:05:11,260 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 502
2019-02-25 16:05:11,260 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 503
2019-02-25 16:05:11,260 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 504
2019-02-25 16:05:11,260 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 505
2019-02-25 16:05:11,260 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 506
2019-02-25 16:05:11,261 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 507
2019-02-25 16:05:11,437 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,441 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,503 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:36000000+3000000
2019-02-25 16:05:11,563 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,564 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,564 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,564 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,564 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,572 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,600 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,600 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,753 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,754 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,760 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,763 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000935645.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,765 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,769 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000012_0
End of LogType:syslog



Container: container_1550090358635_0074_01_000090 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1550090358635_0074_01_000053 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900032835.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:15,365 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:15,419 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:15,419 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:15,428 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:15,428 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:15,593 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:15,770 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:15,917 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:16,264 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:16,274 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:16,293 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:16,294 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:16,294 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:16,294 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:16,294 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:16,294 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:16,294 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:16,294 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:16,294 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:16,383 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:16,386 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:16,433 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:87000000+3000000
2019-02-25 16:05:16,486 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:16,486 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:16,486 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:16,486 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:16,486 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:16,494 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:16,514 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:16,514 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:16,566 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:16,567 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:16,572 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:16,575 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:16,577 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:16,580 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000029_2
End of LogType:syslog



Container: container_1550090358635_0074_01_000056 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000001215.4
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8808
Log Contents:
2019-02-25 16:05:16,367 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:16,420 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:16,420 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:16,428 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:16,428 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:16,588 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:16,768 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:16,920 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:17,272 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:17,282 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:17,300 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:17,300 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:17,300 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:17,300 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:17,301 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:17,301 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:17,301 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:17,301 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:17,301 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:17,393 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,396 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:17,445 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:0+3000000
2019-02-25 16:05:17,507 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:17,507 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:17,507 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:17,507 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:17,507 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:17,514 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:17,535 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:17,535 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:17,589 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:17,590 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:17,596 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:17,599 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000001215.4'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:17,601 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:17,605 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000000_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000087 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1550090358635_0074_01_000035 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003991285.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:08,458 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:08,513 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:08,513 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:08,521 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:08,521 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:08,669 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:08,846 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:08,991 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:09,338 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:09,348 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:09,367 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:09,367 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:09,367 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:09,367 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:09,367 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:09,367 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:09,368 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:09,368 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:09,368 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:09,467 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:09,470 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:09,512 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:84000000+3000000
2019-02-25 16:05:09,572 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:09,572 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:09,572 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:09,572 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:09,572 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:09,580 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:09,600 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:09,600 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:09,664 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:09,665 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:09,671 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:09,673 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:09,676 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:09,679 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000028_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000061 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001218505.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:17,399 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:17,455 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:17,455 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:17,462 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:17,463 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:17,625 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:17,802 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:17,949 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:18,308 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:18,317 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:18,334 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:18,335 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:18,335 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:18,335 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:18,335 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:18,335 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:18,335 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:18,335 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:18,335 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:18,424 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,427 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:18,472 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:42000000+3000000
2019-02-25 16:05:18,511 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:18,512 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:18,512 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:18,512 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:18,512 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:18,519 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:18,538 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:18,539 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:18,594 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,594 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:18,600 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:18,603 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001218505.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,605 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:18,608 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000014_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000093 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout



Container: container_1550090358635_0074_01_000063 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000146835.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8814
Log Contents:
2019-02-25 16:05:17,427 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:17,485 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:17,485 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:17,493 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:17,493 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:17,662 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:17,845 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:17,993 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:18,351 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:18,361 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:18,383 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:18,383 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:18,383 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:18,383 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:18,384 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:18,384 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:18,384 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:18,384 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:18,384 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:18,489 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,492 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:18,538 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:3000000+3000000
2019-02-25 16:05:18,584 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:18,584 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:18,584 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:18,584 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:18,584 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:18,593 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:18,615 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:18,615 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:18,673 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:18,674 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:18,679 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:18,682 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000146835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:18,684 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:18,687 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000001_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000044 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003334585.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:12,357 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:12,412 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:12,412 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:12,420 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:12,420 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:12,583 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:12,754 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:12,895 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:13,237 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:13,248 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:13,272 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:13,272 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:13,272 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:13,273 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:13,273 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:13,273 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:13,273 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:13,273 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:13,274 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:13,375 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:13,378 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:13,423 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:78000000+3000000
2019-02-25 16:05:13,471 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:13,471 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:13,471 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:13,471 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:13,471 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:13,479 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:13,500 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:13,500 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:13,557 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:13,557 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:13,563 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:13,566 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:13,568 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:13,571 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000026_2
End of LogType:syslog



Container: container_1550090358635_0074_01_000042 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003991285.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:11,365 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:11,421 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:11,421 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:11,429 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:11,429 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:11,594 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:11,773 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:11,919 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:12,251 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:12,261 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:12,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:12,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:12,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:12,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:12,280 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:12,281 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:12,281 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:12,281 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:12,281 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:12,379 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:12,382 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:12,427 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:84000000+3000000
2019-02-25 16:05:12,467 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:12,467 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:12,467 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:12,467 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:12,467 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:12,474 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:12,511 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:12,511 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:12,560 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:12,561 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:12,567 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:12,569 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003991285.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:12,571 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:12,575 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000028_2
End of LogType:syslog



Container: container_1550090358635_0074_01_000070 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_002901215.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:18,425 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:18,480 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:18,481 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:18,489 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:18,489 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:18,661 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:18,844 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:18,993 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:19,351 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:19,361 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:19,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:19,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:19,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:19,379 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:19,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:19,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:19,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:19,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:19,380 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:19,483 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:19,486 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:19,533 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:72000000+3000000
2019-02-25 16:05:19,582 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:19,582 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:19,582 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:19,582 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:19,582 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:19,590 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:19,612 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:19,612 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:19,690 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:19,690 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:19,696 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:19,699 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_002901215.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,701 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:19,704 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000024_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000040 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_900032835.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:10,343 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:10,396 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:10,396 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:10,403 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:10,403 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:10,554 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:10,726 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:10,870 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:11,212 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:11,223 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:11,242 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:11,242 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:11,242 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:11,242 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:11,242 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:11,242 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:11,242 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:11,243 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:11,243 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:11,346 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,349 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:11,395 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:87000000+3000000
2019-02-25 16:05:11,460 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:11,460 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:11,460 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:11,460 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:11,460 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:11,468 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:11,490 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:11,491 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:11,548 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:11,549 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:11,554 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:11,556 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_900032835.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:11,559 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:11,562 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000029_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000069 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_000708245.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:18,428 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:18,483 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:18,483 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:18,491 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:18,491 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:18,660 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:18,844 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:18,989 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:19,345 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:19,355 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:19,374 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:19,374 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:19,374 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:19,374 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:19,375 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:19,375 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:19,375 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:19,375 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:19,375 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:19,468 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:19,471 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:19,517 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:30000000+3000000
2019-02-25 16:05:19,561 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:19,561 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:19,561 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:19,561 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:19,562 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:19,569 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:19,588 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:19,589 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:19,648 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:19,648 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:19,654 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:19,657 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_000708245.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:19,659 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:19,663 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000010_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000038 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_003334585.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:09,351 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:09,406 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:09,406 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:09,414 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:09,414 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:09,569 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:09,744 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:09,890 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:10,220 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:10,230 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:10,249 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:10,249 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:10,250 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:10,250 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:10,250 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:10,250 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:10,250 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:10,250 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:10,250 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:10,347 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:10,351 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:10,398 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:78000000+3000000
2019-02-25 16:05:10,450 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:10,450 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:10,450 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:10,450 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:10,450 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:10,458 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:10,488 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:10,488 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:10,614 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:10,615 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:10,621 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:10,623 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_003334585.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:10,627 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:10,631 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000026_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000049 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001859185.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:14,358 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:14,411 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:14,412 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:14,419 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:14,419 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:14,565 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:14,736 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:14,884 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:15,225 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:15,235 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:15,254 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:15,254 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:15,255 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:15,255 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:15,255 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:15,255 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:15,255 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:15,255 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:15,255 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:15,349 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:15,351 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:15,395 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:57000000+3000000
2019-02-25 16:05:15,439 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:15,439 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:15,439 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:15,439 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:15,439 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:15,447 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:15,466 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:15,467 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:15,518 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:15,518 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:15,524 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:15,526 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:15,528 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:15,532 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000019_1
End of LogType:syslog



Container: container_1550090358635_0074_01_000083 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:0
Log Contents:
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:808
Log Contents:
2019-02-25 16:05:20,407 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:20,461 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:20,461 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:20,468 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:20,469 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:20,639 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
End of LogType:syslog



Container: container_1550090358635_0074_01_000078 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001859185.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:19,440 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:19,496 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:19,496 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:19,504 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:19,504 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:19,668 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:19,853 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:19,994 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:20,321 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:20,329 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:20,347 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:20,347 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:20,347 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:20,347 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:20,348 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:20,348 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:20,348 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:20,348 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:20,348 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:20,439 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,442 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:20,482 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:57000000+3000000
2019-02-25 16:05:20,517 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:20,517 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:20,517 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:20,517 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:20,517 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:20,524 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:20,543 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:20,543 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:20,594 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,594 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:20,600 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:20,602 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001859185.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,605 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:20,608 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000019_2
End of LogType:syslog



Container: container_1550090358635_0074_01_000079 on r389.pvt.bridges.psc.edu_46464_1551128727842
===================================================================================================
LogType:stderr
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:2808
Log Contents:
java.io.FileNotFoundException: File does not exist: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/nullassemblers.seq/data
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1309)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1819)
	at org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:456)
	at org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:429)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)
	at org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:408)
	at boa.functions.BoaGenomeIntrinsics.openAssemblerMap(BoaGenomeIntrinsics.java:202)
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:122)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
java.lang.NullPointerException
	at boa.functions.BoaGenomeIntrinsics.getAssembler(BoaGenomeIntrinsics.java:126)
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:133)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
error with genome ID: GCF_001336335.1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.impl.MetricsSystemImpl).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
End of LogType:stderr

LogType:stdout
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:20
Log Contents:
nullassemblers.seq/
End of LogType:stdout

LogType:syslog
Log Upload Time:Mon Feb 25 16:05:27 -0500 2019
LogLength:8815
Log Contents:
2019-02-25 16:05:19,430 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-25 16:05:19,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-02-25 16:05:19,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2019-02-25 16:05:19,496 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2019-02-25 16:05:19,496 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1550090358635_0074, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1b2abca6)
2019-02-25 16:05:19,669 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2019-02-25 16:05:19,854 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /local/RES_hadoop/hdisk1/yarn/usercache/hbagheri/appcache/application_1550090358635_0074
2019-02-25 16:05:20,000 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2019-02-25 16:05:20,353 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2019-02-25 16:05:20,363 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-02-25 16:05:20,381 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 480
2019-02-25 16:05:20,381 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 481
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 482
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 483
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 484
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 485
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 486
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 487
2019-02-25 16:05:20,382 WARN [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 488
2019-02-25 16:05:20,475 WARN [main] org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory: error creating DomainSocket
java.net.ConnectException: connect(2) error: No such file or directory when trying to connect to '/local/RES_hadoop/.shortcircuitpath'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:250)
	at org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory.createSocket(DomainSocketFactory.java:164)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextDomainPeer(BlockReaderFactory.java:752)
	at org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfo(BlockReaderFactory.java:470)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.create(ShortCircuitCache.java:782)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.fetchOrCreate(ShortCircuitCache.java:716)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getBlockReaderLocal(BlockReaderFactory.java:422)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:333)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:656)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:882)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:471)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:358)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:754)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,478 WARN [main] org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache: ShortCircuitCache(0x45cff11c): failed to load 1073751577_BP-1048571735-10.4.217.131-1547646479524
2019-02-25 16:05:20,523 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/dataset/genomes.seq:45000000+3000000
2019-02-25 16:05:20,565 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2019-02-25 16:05:20,565 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2019-02-25 16:05:20,565 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2019-02-25 16:05:20,565 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2019-02-25 16:05:20,565 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2019-02-25 16:05:20,573 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-02-25 16:05:20,594 INFO [main] org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2019-02-25 16:05:20,595 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2019-02-25 16:05:20,654 ERROR [main] boa.runtime.BoaMapper: Job0: java.lang.NullPointerException caught
java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
2019-02-25 16:05:20,655 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2019-02-25 16:05:20,661 INFO [main] org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2019-02-25 16:05:20,663 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: map failure for key 'GCF_001336335.1'
	at boa.Asm$AsmBoaMapper.map(Asm.java:158)
	at boa.Asm$AsmBoaMapper.map(Asm.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
	at boa.Asm$AsmBoaMapper$Job0.map(Asm.java:135)
	at boa.Asm$AsmBoaMapper.runJob(Asm.java:164)
	at boa.Asm$AsmBoaMapper.map(Asm.java:155)
	... 9 more

2019-02-25 16:05:20,665 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2019-02-25 16:05:20,669 WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://r383.opa.bridges.psc.edu:8020/user/hbagheri/tmp/asmFeb25OUTUT/_temporary/1/_temporary/attempt_1550090358635_0074_m_000015_2
End of LogType:syslog

